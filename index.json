[{"content":"Let\u0026rsquo;s say you want to execute some tasks. Since executing it through a single thread might take you quite some time to get the result, you decide to use the ever dependable ExecutorService to process it through multiple threads.\nHere\u0026rsquo;s a sample:\npublic static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(5); for (int i = 0; i \u0026lt; 5; i++) { int temp = i; executorService.submit(() -\u0026gt; { task(temp); }); } executorService.shutdown(); System.out.println(\u0026#34;ExecutorService is shutdown\u0026#34;); } private static void task(int temp) { try { TimeUnit.SECONDS.sleep(1L); System.out.println(\u0026#34;Task \u0026#34; + temp + \u0026#34; completed\u0026#34;); } catch (InterruptedException e) { throw new RuntimeException(e); } } Of course, as usual, no example of Threads is ever complete without using \u0026ldquo;sleep\u0026rdquo; as an archetype of task execution.\nIt outputs,\nExecutorService is shutdown Task 1 completed Task 2 completed Task 0 completed Task 4 completed Task 3 completed Now imagine there\u0026rsquo;s an endless queue of tasks, the number of which you don\u0026rsquo;t know about. Maybe they are determined by the number of entries in a database which get added dynamically.\nFor example, a bank, wherein which it has to process a number of transactions throughout the day. The transaction end time will be 5 PM, beyond which it will not accept any additional tasks.\nHowever, you do know that the number of tasks will be finite, and will end at some point of time.\nHow do you know the point in time when all the tasks have completed?\nIf you notice the above code snippet, the ExecutorService.shutdown() enables the main thread to exit immediately, but the background threads still process the accepted tasks to completion. Is there a way when you can get notified about the completion?\nA couple of solutions come to mind:\nUse a CountDownLatch to count the tasks - but since you don\u0026rsquo;t know the number of tasks, it\u0026rsquo;s impractical to use it. Use ExecutorService.awaitTermination(). However, the time here is still undeterministic. You can use a very liberal ExecutorService.awaitTermination(Long.MAX_VALUE, TimeUnit.DAYS) or something similar. But that is again a blocking call. Is there a better way to solve this?\nJava does provide a better and relatively unknown way to get around this. The \u0026ldquo;trick\u0026rdquo; here is to know that Executors.newFixedThreadPool is essentially a ThreadPoolExecutor with predefined values. Let\u0026rsquo;s check the implementation of Executors.newFixedThreadPool.\npublic static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;()); } I really recommend to read the doc for ThreadPoolExecutor here. ExecutorService is a convenient wrapper over ThreadPoolExecutor.\n\u0026hellip; programmers are urged to use the more convenient Executors factory methods Executors.newCachedThreadPool() (unbounded thread pool, with automatic thread reclamation), Executors.newFixedThreadPool(int) (fixed size thread pool) and Executors.newSingleThreadExecutor() (single background thread), that preconfigure settings for the most common usage scenarios.\nThe section that will help us resolve out problem is:\nHook methods This class provides protected overridable beforeExecute(Thread, Runnable) and afterExecute(Runnable, Throwable) methods that are called before and after execution of each task. These can be used to manipulate the execution environment; for example, reinitializing ThreadLocals, gathering statistics, or adding log entries. Additionally, method terminated() can be overridden to perform any special processing that needs to be done once the Executor has fully terminated.\nWe can use the terminated method to notify us of the same! But how do we use it?\npublic static void main(String[] args) { ExecutorService executorService = new ThreadPoolExecutor(5, 5, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;\u0026gt;()) { @Override protected void terminated() { super.terminated(); System.out.println(\u0026#34;ExecutorService is terminated\u0026#34;); } }; for (int i = 0; i \u0026lt; 5; i++) { int temp = i; executorService.submit(() -\u0026gt; { task(temp); }); } executorService.shutdown(); System.out.println(\u0026#34;ExecutorService is shutdown\u0026#34;); } private static void task(int temp) { try { TimeUnit.SECONDS.sleep(1L); System.out.println(\u0026#34;Task \u0026#34; + temp + \u0026#34; completed\u0026#34;); } catch (InterruptedException e) { throw new RuntimeException(e); } } If you do not prefer Anonymous classes (like me), you can always extend ThreadPoolExecutor yourself to create a custom one.\npublic static void main(String[] args) { ExecutorService executorService = getThreadPoolExecutor(); for (int i = 0; i \u0026lt; 5; i++) { int temp = i; executorService.submit(() -\u0026gt; { task(temp); }); } executorService.shutdown(); System.out.println(\u0026#34;ExecutorService is shutdown\u0026#34;); } private static ThreadPoolExecutor getThreadPoolExecutor() { return new CustomThreadPoolExecutor(5, 5, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;\u0026gt;()); } static class CustomThreadPoolExecutor extends ThreadPoolExecutor { public CustomThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue) { super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); } @Override protected void terminated() { super.terminated(); System.out.println(\u0026#34;ExecutorService is terminated!\u0026#34;); } } private static void task(int temp) { try { TimeUnit.SECONDS.sleep(1L); System.out.println(\u0026#34;Task \u0026#34; + temp + \u0026#34; completed\u0026#34;); } catch (InterruptedException e) { throw new RuntimeException(e); } } Here\u0026rsquo;s the output to verify if it works as per our expectations.\nExecutorService is shutdown Task 0 completed Task 3 completed Task 2 completed Task 4 completed Task 1 completed ExecutorService is terminated What are some other relatively unknown snippets you use? Let me know in the comments!\n","permalink":"https://darshit.dev/posts/tracking-threadpool-termination/","summary":"\u003cp\u003eLet\u0026rsquo;s say you want to execute some tasks. Since executing it through a single thread might take you quite some time to get the result, you decide to use the ever dependable \u003ccode\u003eExecutorService\u003c/code\u003e to process it through multiple threads.\u003c/p\u003e","title":"Mastering ExecutorService Shutdown: Tracking ThreadPool Termination"},{"content":"I went into reading this book with high expectations, and I was\u0026hellip; disappointed? But that\u0026rsquo;s probably on me.\nI wanted something which inspires me to explore the rich Indian culture that I know only sparsely about, at the same time holding my hand over the things I don\u0026rsquo;t know. It does do the former very well, but the latter, not so much. A lot of questions are answered, but it raises even more questions the more you read.\nMy biggest gripe with this book is, it doesn\u0026rsquo;t explain things sufficiently well (to me). The author assumes that the reader would already probably know of it because they\u0026rsquo;re clearly clever enough to pick up this book to read. But even as a person already knowing the general concepts - a lot of it was assumed to be already known by the reader. This leads me to probably miss a lot of context and the references that I should be seeing, but in the author\u0026rsquo;s defence, there\u0026rsquo;s just too many references in Indian literature. However, I still would have wanted to have things slow, and in a bit of an ELI5 form. Web links would also have worked. But I\u0026rsquo;m not 5, nor am I a millennial (or am I? I always forget where the line lies. Google answers - yes, I\u0026rsquo;m a millennial).\nAnyway, if you\u0026rsquo;re a millennial like me, you\u0026rsquo;re probably not understanding a lot of it in this book. Perhaps you have an exceptional family who know and already follow the scriptures, but for someone like me whose family is moderately religious, and only follows certain traditional rituals, you\u0026rsquo;ll be scratching your heads, just like I did. Not your fault, though. Honestly, I probably disappointed Bibek Debroy ji, and I really admire him as an author and as a person who is probably the one who lit the fire in me for Indian culture.\nTo Bibek ji\u0026rsquo;s credit, he admits that the book is more of something that inspires exploration, and deliberately misses answering the questions that might arise in our minds. As a person of an honest scientific temperament, he refuses to opine on things in this book, and strictly sticks to facts and literal translations, as like his other books. He does open us up to a world unknown, the shlokas from Vedas, the Devi Bhagvata Purana, shlokas from Adi Shankaracharya, the numerous and always changing Shaktipeethas, the ways of worship, the forms of Devi, the descriptions of Devi, the characteristics, and how it ties into the worship of the Brahman. And it\u0026rsquo;s beautiful. To think that people wrote all of this, in praise of the divine femininity, is an eye-opener to the rich culture and thinking that India has had. And this text is not even touching the surface!\nWhen I started to read the book, I decided that I\u0026rsquo;d probably read each Sanskrit shloka mentioned by myself. However, my skill as a reader of Sanskrit/Devanagari was questioned, and admittedly, I didn\u0026rsquo;t satisfy that very well, so much so that I questioned if I even knew it in the first place! If I did try to read all the shlokas, I would have been much more likely to mess it up with a different meaning altogether. Not to mention the additional 3-5 months it would take me to complete this book, by the time I probably would have abandoned it. With this respect, it is good to know what Shloka\u0026rsquo;s are just words. Shlokas aren\u0026rsquo;t magical words, which, if spoken, will grant you your desires. Well, they will, but not if you don\u0026rsquo;t understand what you\u0026rsquo;re speaking/reading. Remember the power of manifestation? Or quotes like \u0026ldquo;You are as you think\u0026rdquo;. It\u0026rsquo;s true. And it always has been. And we\u0026rsquo;ve lost touch with enough Sanskrit to just repeat the shlokas verbatim without thought. I thought it\u0026rsquo;d be a better idea, practically, and for easier comprehension to just read the English meaning of the shlokas.\nWould I recommend this book to be read by everyone? No, not really. Casual readers would just zone out. Non readers would probably keep it as a show-piece. Should you read it, though? Yes, at least once. It will probably ignite the fire that you had always been dreaming of, or at least let you know that you have to still learn a lot.\nTo put it in Bibek ji\u0026rsquo;s words:\n[Devi] is the one who made me write it. She is the one who will make you read it or ignore it. Ya Devi sarvagrantheshu! Nothing more needs to be said.\nJust after I wrote the review, I found this tweet by Nassim Nicholas Taleb: https://twitter.com/nntaleb/status/1871573854717636636\nA convincing argument of the role of language is the existence of surviving holy languages, uncorrupted by the no-nonsense tests of daily use. Semitic religions, that is Judaism, Islam, and original Christianity understood the point; keep a language away from the rationalization of daily use and avoid the corruption of the vernacular. Four decades ago, the Catholic church translated the services and liturgies from Latin to the local vernaculars; it can be argued that this caused a drop in religious beliefs. Suddenly religion subjected itself to being judged by intellectual and scientific, without the aesthetic, standards.\nHow relevant do you think would this be for Sanskrit?\n","permalink":"https://darshit.dev/posts/review-devi-for-millennials/","summary":"\u003cp\u003eI went into reading this book with high expectations, and I was\u0026hellip; disappointed? But that\u0026rsquo;s probably on me.\u003c/p\u003e\n\u003cp\u003eI wanted something which inspires me to explore the rich Indian culture that I know only sparsely about, at the same time holding my hand over the things I don\u0026rsquo;t know. It does do the former very well, but the latter, not so much. A lot of questions are answered, but it raises even more questions the more you read.\u003c/p\u003e","title":"Devi for Millennials, by Bibek Debroy - A Review"},{"content":"You heave a sigh of relief, as the QA has approved a long-awaited feature for deployment on Prod. However, as a part of the process, it is first deployed on the UAT env, where there are test accounts that can be used to certify the feature works outside of the local developer and QA testing systems.\nBut\u0026hellip; running the test suite results in a lot of failures!\nReply with the always relevant \u0026ldquo;But it works on my machine!\u0026rdquo;\nWhat do you do? You\u0026rsquo;re sure that the code works. Defintely sure. Maybe the problem is with the UAT environment then? But what could be the problem with the environment? Maybe the test accounts which are newly created, are configured incorrectly? Probably yes, you think. You have access to the logs for the environment, but the scenario which it is failing for, has limited to no logs to identify the problem. You internally curse your ancestral developers.\nAnother option? Remote debugging! While this is a good idea, it is seldom practical for environments where the apps are under constant use. If your code is in the \u0026ldquo;hot path\u0026rdquo;, good luck figuring out what requests are yours. Also it may slow down the app significantly.\nEssentially, what you want is to debug the application, as if it was deployed on your local machine, but the database of the UAT server. But since UAT server is not directly accessible to your local application, you\u0026rsquo;re out of luck.\nOr are you? Fret not, because an SSH Tunnel is here to your rescue.\nSSH Tunnel What is an SSH Tunnel? And how do I use it?\nShort answer:\nSSH Tunneling will allow your application to behave as if it is deployed on a remote system, through which the UAT database is accessible.\nLong answer:\nThe Linux ssh command provides a functionality to \u0026ldquo;port forward\u0026rdquo;. Admittedly, the term \u0026ldquo;port forward\u0026rdquo; is pretty non-descriptive. Hence, I\u0026rsquo;ll let StackOverflow provide to you a detailed, and a far easier explanation of SSH Tunneling than what I can here. You can read it here: https://unix.stackexchange.com/a/115906. I recommend you to read the answer because it has diagrams that are far easy to understand than the text based answers.\nHowever, I\u0026rsquo;ll still copy the relevant sections here.\nssh -L 123:farawayhost:456 remotehost local: -L Specifies that the given port on the local (client) host is to be forwarded to the given host and port on the remote side. ssh -L sourcePort:forwardToHost:onPort connectToHost means: connect with ssh to connectToHost, and forward all connection attempts to the local sourcePort to port onPort on the machine called forwardToHost, which can be reached from the connectToHost machine.\nExample For our use case, our sample command will be:\nssh -L \u0026lt;Local Port\u0026gt;:\u0026lt;UAT Database IP\u0026gt;:\u0026lt;UAT Database Port\u0026gt; \u0026lt;JumpHost IP\u0026gt; Note, here the JumpHost is a system which can connect to \u0026lt;UAT Database IP\u0026gt; with the port \u0026lt;UAT Database Port\u0026gt;.\nOnce we have this figured out, everything else is a cakewalk!\nYou can simply run the command, and you\u0026rsquo;ll be able to access the UAT Database on your localhost:\u0026lt;Local Port\u0026gt;. Almost feels like magic!\nIf you need to connect to multiple databases, you will need to run this command multiple times. Or you can write a bash script which can dynamically read a config file to open multiple SSH Tunnels.\nI, being a Java programmer, would rather deal with statically compiled Java code, than worry about a dynamically typed language like bash. So, I utilized the jsch library to whip up an extensible project, which creates and maintains multiple SSH Tunnels. You can check it out here: https://github.com/darshitpp/java-ssh-tunnel\nStructure java-ssh-tunnel └── src └── main ├── java │ └── dev │ └── darshit │ └── java_ssh_tunnel │ ├── Main.java │ ├── MultiTunneler.java │ ├── Tunneler.java │ └── ssh │ ├── TunnelDetails.java │ └── UserDetails.java └── resources Usage Download the project Load up in your IDE Run mvn clean install Change Main.java with required details like SSH username, SSH password, JumpHost sshHost (Optional) Maybe load up localPort, remoteHost, and remotePort details from a file Run Main.java If all things go well, you\u0026rsquo;ll see the following output on your stdout\nStarting tunneling... \u0026lt;remoteHost\u0026gt;:\u0026lt;remotePort\u0026gt; is available on localhost:\u0026lt;localPort\u0026gt; Press Enter to terminate the tunnels... Caveats While the above is very convenient, DO NOT USE IT TO CONNECT TO PROD. Yes, that had to be written in bold with emphasis. Shall I print the message to stderr too? Comment below.\n","permalink":"https://darshit.dev/posts/java-ssh-tunnel/","summary":"\u003cp\u003eYou heave a sigh of relief, as the QA has approved a long-awaited feature for deployment on Prod. However, as a part of the process, it is first deployed on the UAT env, where there are test accounts that can be used to certify the feature works outside of the local developer and QA testing systems.\u003c/p\u003e","title":"SSH Tunnelling with Java"},{"content":" Running specific commands with sudo using Ansible It seems a trivial use case, but it\u0026rsquo;s not. Consider a situation when you\u0026rsquo;re not the user allowed a full sudo access on the remote machine. However, you are only allowed the sudo access on certain commands, which, of course, requires a password. For example, starting or stopping a service.\nAnsible allows privilege escalation, but that will not solve your problem because:\nElevated access is changed to the user root by default Elevated access requires a password, i.e. password for the root user You obviously don\u0026rsquo;t have access to the root user.\nThere are a couple of other directives you can use, which the ansible doc makes it hard to understand even though it tries to be simple in language. You can try to use the ansible_become_user to change to another user while escalating the privilege besides root. However, if you are already the user who has the sudo command access, this will not help.\nIf you have access to change (or get changed) the /etc/sudoers file, you can change the sudo command to be run through NOPASSWD.\nIf you are here, it is likely that you do not have the permissions to change the sudoers file either.\nResolution I saw a couple of workarounds mentioned across Github1, StackOverflow2, and Reddit34, but they were outdated, and didn\u0026rsquo;t work for me.\nOne of the solution5 suggests to use sudo with -S and echo the password from the terminal. This will, however, probably leak your password on the shell, and we don\u0026rsquo;t want this, do we?\nHowever, is there a way Ansible can input the password to sudo? Yes! Perhaps we can use something like the -y flag that is often used to skip prompts of yes/no on the terminal. Thankfully, Ansible is built over Python, and most Python modules are available within Ansible. \u0026ldquo;How does that help?\u0026rdquo;, you ask. Python has a very helpful module called pexpect. Similarly, Ansible has expect.\n- name: Stop service ansible.builtin.expect: command: \u0026#34;sudo systemctl stop service\u0026#34; responses: (?i)password: \u0026#34;{{ pass }}\u0026#34; no_log: true This solves our problem! We can load this password through Ansible vault, and pass it in without being logged anywhere! We also do not have to rely on having access or permissions through the /etc/sudoers file, saving a lot of headache of trying to get approvals.\nProblem: Can\u0026rsquo;t use sudo command-limiting in Ansible\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSpecify sudo password for Ansible\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHow do I run sudo commands with another user\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBecome sudo with limited sudo privileges\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHack using Ansible raw\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://darshit.dev/posts/partial-sudo-ansible/","summary":"\u003chr\u003e\n\u003ch3 id=\"running-specific-commands-with-sudo-using-ansible\"\u003eRunning specific commands with sudo using Ansible\u003c/h3\u003e\n\u003cp\u003eIt seems a trivial use case, but it\u0026rsquo;s not. Consider a situation when you\u0026rsquo;re not the user allowed a full sudo access on the remote machine. However, you are only allowed the sudo access on certain commands, which, of course, requires a password. For example, starting or stopping a service.\u003c/p\u003e","title":"Handling limited sudo access through Ansible"},{"content":"We know about companies using Dark Patterns (more on this post by TechCrunch: WTF is dark pattern design?), and how they affect users. But can there be something like a \u0026ldquo;Stupid Pattern\u0026rdquo;? A thing that most companies do, and they don\u0026rsquo;t even realize it\u0026rsquo;s stupid? This blog post is a part real-life case study, and a major rant about one such pattern that is almost definitely, very stupid.\nIt\u0026rsquo;s mostly a rant, though I encourage you to read how it came to be that way.\nGazon Communications/Razorpay My first experience of a \u0026ldquo;stupid pattern\u0026rdquo; was with Gazon Communications and RazorPay. Gazon is an internet provider, and RazorPay is a payments processor. In May 2019, I received the following email:\nGazon Welcome Email\nThe plaintext password notwithstanding, the email surprised me because I definitely did not sign up for it. I received an additional email with an invoice for the payment. Gazon Payment Invoice\nYes, the email provided in the invoice is mine, but the name and the address do not match (obviously)! I assumed it to be just another typo by the user during the registration/signing up. I thought it would be best to ignore it. These typos happen, and assumed that when the user realized their mistake, they would promptly go correct it.\nI was wrong. The user never realized the \u0026ldquo;mistake\u0026rdquo;. I received more such emails in the following months.\nFed up, I contacted the phone number mentioned in the original invoice.\nWhatsApp chat with my alter ego\nThe person was clueless. I reached out to him in January 2020, but routinely received emails till May 2020.\nI never received any further emails because the user probably never recharged his internet subscription.\nThis wasn\u0026rsquo;t even a spam email!\nBigbasket Bigbasket is one of the major Indian e-commerce companies, catering to delivering fresh vegetables, and other edibles. I did have an account with them, but did not buy anything when I created the account. All of a sudden, 3 years later, I start receiving emails with OTPs, and even a recharge receipt!\nThank you Bigbasket for free credits!\nSomeone just used my email on their account, and Bigbasket didn\u0026rsquo;t even care to verify if the email indeed belonged to them! I also received their phone number in one of the emails. This time, I decided to not contact the person, and instead directly reached out to Bigbasket to close/delete the account. It took 15 emails to even try to explain them the problem. They did not understand, and the issue, to this date, remains unresolved. My account still exists on the platform, and is not deleted yet, despite repeated requests.\nWish.com To be honest, I did not even know about this site until I received the email of me \u0026ldquo;Signing up\u0026rdquo; on their website. Moreover, the email looked like obvious spam.\nNikl (probably a Nickelback fan)\nIt was ridiculous! Even the name did not match this time! I reset the password of the Wish.com account (did not click any link in the email), and noticed that the person had ordered a couple of items. I immediately cancelled the order. The good thing is, they also have an option of deleting the account, and I did so. I was genuinely puzzled now. Was my email so common and prone to typos? It didn\u0026rsquo;t seem likely because it\u0026rsquo;s not even the usual format of firstName.lastName. Weird!!\nPantaloons It\u0026rsquo;s now going too far. Pantaloons is a major garment retailer in India, and I had apparently shopped at one of their stores in Ahmedabad.\nMy Alter Ego on a Shopping spree\nThis time I decided to click on the link in the email. The email wasn\u0026rsquo;t a spam one, and to my surprise, it opened up with details of the order!\ndarshit kanshara buying trousers on Pantaloons\nThe page also had a link for \u0026ldquo;Completing my profile\u0026rdquo;. I clicked on the link, and see what I find:\ndarshit kanshara\u0026rsquo;s profile\nI now had his name, phone number, and date of birth! If I was enterprising and a \u0026ldquo;hacker\u0026rdquo; enough, I could even find a way to scam him out of some money. This was a one off invoice payment, and there was no \u0026ldquo;Unsubscribe\u0026rdquo; button, so I couldn\u0026rsquo;t even \u0026ldquo;report\u0026rdquo; it to someone. I decided to not bother poor Darshit Kanshara with my email troubles.\nJio Jio is a mobile carrier, credited with disrupting the market with very cheap internet plans. I am already a customer, and so I was very surprised when I received another email linking my email to another phone number (not mine).\nEmails from Jio\nI was livid now. How can multiple people make mistakes in their email, especially when my name itself is not very common?! Do notice the last email in the above screenshot, dated 02/07/2018. It says my email has been verified, but it\u0026rsquo;s been verified with a different phone number that\u0026rsquo;s actually mine. Jio probably already thought my email is verified, and linked it to another number without any verification!\nI deactivated the SIM card. The person re-activated it. There was also no other way to change email except an OTP to the linked number!\nRBL Bank/Bajaj-Finserv Bank The above emails were pretty random. Imagine my surprise when I received an email from a Credit Card company/Bank!\nRBL Bank being large hearted and sharing Credit Card PINs\nThe above emails have Credit Card application forms, and PINs. Though, the PDFs are in an encrypted format. How is the encryption, you ask?\nI\u0026rsquo;ll let one of the emails answer you.\nHow complicated can it be?\nAll it takes to access the password protected form is a 10 character password. But is it really a 10 character password? I already know the characters of my name. How hard is it to get the date of birth? It\u0026rsquo;s a simple 30 line python script. How had the person missed noticing no email statements or PIN for the Credit Card?\nI decided to \u0026ldquo;crack\u0026rdquo;/\u0026ldquo;hack\u0026rdquo; the PDF, and contact the person. It took me just 15 mins to decrypt the PDF. I reached out to the guy, and he, like others earlier, had no clue about the wrong email!\nspeechless\u0026hellip;\nThis was bonkers! Some person actually mistyped his whole email (and both of ours don\u0026rsquo;t have a similarity except the first name). If I wanted, I could actually decrypt the document with the PIN, and hack all accounts of the said person. Decrypting merely the application form gave me the address, phone number, and other personal information. In the hands of a malicious agent, the said person could be looking at a potential ruin to their whole life savings, and identity theft.\nAnd most companies don\u0026rsquo;t even care to validate the \u0026ldquo;KYC\u0026rdquo;.\nIf you thought this was enough confusion, I received another email yesterday\u0026hellip;\nBooking.com Some good samaritan booked a room with King sized bed for me in Hyatt Regency Toronto, for 15 days in March 2022!\n#Lucky\nAgain, the actual name is not mine (except the first name). He booked it for 15 days with it amounting to more than $3K CAD. How lucky (or unlucky) I am! #Blessed\nI actually again contacted Booking.com through their helpline number. I already had the confirmation number and the PIN associated with the booking. The customer support instead asked me to confirm my name, which I replied to. They said that the name matches, and then asked me if I wanted to cancel the booking if I want. What!? They continued that as I had the confirmation number and the PIN, and even the name matched (only the first name, mind you), I would be able to cancel a booking worth more than $3K CAD.\nI questioned about how they sent me an email without confirming it was indeed me booking the hotel, they replied that it\u0026rsquo;s the concern of the person booking the hotel/room! \u0026ldquo;No company provides the email verification service\u0026rdquo;, they said, and if I had so much of a problem with the emails, I could just unsubscribe. That\u0026rsquo;s obviously not the point I\u0026rsquo;m trying to make!\nImagine the whole internet running on an element of \u0026ldquo;trust\u0026rdquo;, and no verification! This is what I call a \u0026ldquo;Stupid Pattern\u0026rdquo;. It\u0026rsquo;s not a Dark Pattern, but the chink in the armour will make internet users fail all around. All the point of digital security fails when someone mistypes their email, or someone else does. Why hasn\u0026rsquo;t someone not even thought of this? Product Managers? All the people stressing on UI/UX?\nA solution would be mandatory verification of emails, and as described above, not many companies do that. Even verification of emails has its problems. A typo to the email, may lead to a malicious actor \u0026ldquo;confirming\u0026rdquo;/\u0026ldquo;verifying\u0026rdquo; the email, and there goes your bank account. Now think about how many people use the internet, and don\u0026rsquo;t know about basic online safety measures like a strong password, or ad-blockers, encountering something like this? And potentially on the wrong side of things!\nI have thought about what is it about my email that leads to me getting legitimate emails like the above. I\u0026rsquo;m sure you\u0026rsquo;re now thinking about it too. But I\u0026rsquo;ve never found a satisfactory answer, because an email is not inherently \u0026ldquo;secret\u0026rdquo; like a password is. There is no problems with emails \u0026ldquo;leaking\u0026rdquo; out, unlike passwords. And I can only hope someone is not getting my emails. I don\u0026rsquo;t even want to think of the problems that would lead me to.\nThese aren\u0026rsquo;t spam emails, and Gmail is pretty good at flagging them.\nMy email cannot be deliberately mistyped. The person whose bank emails I received has 6 more characters than my personal email.\nIs it a deliberate attempt/consipiracy by some group of people or hackers?\nI\u0026rsquo;m not sure.\nIf you\u0026rsquo;re a computer/cyber security expert reading this, can you suggest any steps I could take to prevent this \u0026ldquo;spam\u0026rdquo;?\nShall I use a new email service with a custom domain? Any cheap ones that you might want to recommend?\nIf you\u0026rsquo;re a normal person reading this \u0026ndash; you might want to check if the bank (and other) services you use have the correct email configured.\nWe, as internet citizens, must also ask for laws redressing these types of lapses by the companies. Non-EU people who do not have the luxury of GDPR must demand similar laws of their governments. Services that you use must have the provision of deleting your account at the very least.\nFollow more of this discussion on HackerNews.\n","permalink":"https://darshit.dev/posts/stupid-patterns/","summary":"\u003cp\u003eWe know about companies using \u003ca href=\"https://www.shopify.com/partners/blog/dark-patterns\"\u003eDark Patterns\u003c/a\u003e (more on this post by TechCrunch: \u003ca href=\"https://techcrunch.com/2018/07/01/wtf-is-dark-pattern-design/\"\u003eWTF is dark pattern design?\u003c/a\u003e), and how they affect users. But can there be something like a \u0026ldquo;Stupid Pattern\u0026rdquo;? A thing that most companies do, and they don\u0026rsquo;t even realize it\u0026rsquo;s stupid? This blog post is a part real-life case study, and a major rant about one such pattern that is almost definitely, very stupid.\u003c/p\u003e","title":"Stupid Patterns"},{"content":"I currently work as a Software Engineer with Gupshup.\nI am involved in the computing community by volunteering at ACM. I have been an editor with ACM XRDS, and I\u0026rsquo;m now a member of the ACM Future of Computing Academy (FCA). You can find the work that FCA is doing at https://acm-fca.org/\nMy professional work and interests include working with Java, Spring Boot and related ecosystems, and learning about designing Scalable Software Architectures and Systems.\nMy favourite IDE is IntelliJ IDEA!\nYou can reach out to me on Twitter @darshitpp and LinkedIn, and you can find my Resume/CV here.\nYou can find a text based resume below.\nExperience Software Engineer, Gupshup Technology, May 2020 - Present Reduced Application shutdown time by 800x (40mins to 3s) by optimizing and using safe Thread stopping strategy. Introduced Token based authentication for APIs. Used Redis Cluster with Lua scripts to enable limits on messages sent as per client configuration. Eliminated deployment of production instances from 100s to 0 by enabling dynamic data update. Implemented security in MongoDB connections through application to prevent unauthorized access. Implemented Unit testing strategies to ensure code reliability. Software Engineer (Spring Boot), LogiNext Solutions, December 2018 - May 2020 Secured sensitive application secrets like credentials and passwords by utilizing server side encryption with the help of AWS Key Management Service and AWS S3 storage. Reduced costs by implementing a caching mechanism for Google Places and Geocoding API, OneMap, and Open Street Maps calls. Implemented a Redis based debounce to eliminate duplicate transactions in the system. Reduced Redis usage by 50% by optimizing storage strategies. Contribued to migration of the application from Spring Boot v1.5 to v2.1.4 Software Engineer (Spring Boot), KPIT Technologies, July 2016 - November 2018 With CRISIL: Quantix Mutual Funds Screener, and Wealth Tracker\nImplemented a REST micro-service which enables a user to shortlist Mutual Funds based on a criteria. Introduced Annotation based development to the team that reduced development time by 40+ man hours per week. Implemented a system which generates user portfolio reports based on their investments profiles and existing portfolios. Project Intern, Persistent Systems, June 2015 – May 2016 Developed a smart system called Dactylock, to secure information using Biometrics and Secret Sharing Techniques as a part of Final Year Bachelors’ Project. Languages and Technologies Java; Spring Boot; Lua; TDD MySQL; Redis; MongoDB IntelliJ IDEA; Git; SVN Oracle Cloud; Github Actions for CI/CD Side Projects Google Maps Java SDK. Implemented a feature to ensure consistence between the Java and JS SDK. Enabled parsing of API Responses in the Google Maps Java SDK. Technologies: Java\nJava URL Shortner. Created a self-hosted production ready URL shortener webapp and CLI. Deployed on Oracle Cloud. Technologies: Spring Boot, Docker, Java, PicoCli, GraalVM, Oracle Cloud\nSDKMAN! is a tool for managing parallel versions of multiple SDKs on any Unix based system. Improved error suggestions for the user. Technologies: Java, Cucumber\nStock Price Bot. A bot which shows the most recent Equity and Cryptocurrency prices. Technologies: Python\nAchievements \u0026amp; Awards ACM Future of Computing Academy: Selected as a member of ACM Future of Computing Academy which aims to shape the future of the computing profession. See: Bookmarking and Beyond: Building the Pointer to Quality Knowledge\nACM Selects: ACM Selects are a series of guides to a broad range of topics in computer science. Check out some of the guides I compiled: Getting Started with Microservices, and Spotlight on Computing in India\nFeatured in Java Annotated Monthly: My article on Using IntelliJ IDEA Live Templates was featured in the \u0026ldquo;Java Tutorials \u0026amp; Tips\u0026rdquo; section in the March 2020 issue of Java Annotated Monthly by Trisha Gee\nFeatured in The Awesome Java Weekly: My blog on Dynamic Enums was featured in Awesome Java Weekly Newsletter #268\nACM Crossroads: Special Projects Editor, and Departments Editor for Conferences section of the Magazine. More info: https://xrds.acm.org/aboutus.cfm#darshit\nDelighted Customer: Received great ratings from our client CRISIL twice for being a fast learner and contribution to the projects\nNASSCOM India@75 Hackathon Winner: Developed an Android marketplace for blue-collar jobs in the unorganized sector.\nHonourable Mention at ACM ICPC Amritapuri Regionals, 2015\n","permalink":"https://darshit.dev/about/","summary":"\u003cp\u003eI currently work as a Software Engineer with \u003ca href=\"https://gupshup.io\"\u003eGupshup\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eI am involved in the computing community by volunteering at ACM. I have been an editor with ACM \u003ca href=\"https://xrds.acm.org/\"\u003e\u003cstrong\u003eXRDS\u003c/strong\u003e\u003c/a\u003e, and I\u0026rsquo;m now a member of the ACM \u003ca href=\"https://www.acm.org/fca/\"\u003e\u003cstrong\u003eFuture of Computing Academy (FCA)\u003c/strong\u003e\u003c/a\u003e. You can find the work that FCA is doing at \u003ca href=\"https://acm-fca.org/\"\u003ehttps://acm-fca.org/\u003c/a\u003e\u003c/p\u003e","title":"About"},{"content":"But can one even make Enums dynamic? Enums, by definition, are static. They are used to \u0026ldquo;predefine\u0026rdquo; constants. I\u0026rsquo;ll let the official Oracle Java Tutorial on Enums to help explain the definition.\nAn enum type is a special data type that enables for a variable to be a set of predefined constants. The variable must be equal to one of the values that have been predefined for it. Common examples include compass directions (values of NORTH, SOUTH, EAST, and WEST) and the days of the week.\npublic enum Day { SUNDAY, MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY } The values of an enum are known to the compiler at compile time, are not supposed to change. Imagine if someone tried to introduce a new day of the week. This is pretty unlikely, and thus, for all intents and purposes, the days of the week remain the same.\nHowever, you are now working on an application which has a legacy codebase. This legacy code has an enum named Colour (the British spelling, because I\u0026rsquo;m not in the US). The actual enum might be something different and complicated, but the example of Colour works for the purposes of this article.\nColour has three colours defined inside it \u0026ndash; RED, GREEN, and BLUE.\npublic enum Colour { RED(255, 0, 0), GREEN(0, 255, 0), BLUE(0, 0, 255); int r, g, b; Colour(int r, int g, int b) { this.r = r; this.g = g; this.b = b; } // getters and toString() } The Colour enum is being used across lots of applications as a dependency. First, you wonder why someone needed to put the Colours as an Enum datatype. But unable to do anything about it, you just accept it and work with whatever is in your fate.\nThe problem with the above enum is, every time some app needs a new colour, you need to add the new colour to your codebase. After adding a new colour, you now need to test, and then re-deploy all your applications. This has to be done every time a new colour is requested. You see the problem \u0026ndash; the colours are supposed to be dynamic, but someone took a decision an eternity ago, and now you are the one in soup.\nYou now want to change enums to make them dynamic, so that any new colour added, is picked up from a database, with minimal code changes across your stack. How do you proceed?\nEnums are also classes Yes! Enums are also classes. We know that enums are static, and classes are not. Technically, you could replace Enum with a class. If you replace an Enum with a Class, you would not even need to change imports in other classes. No part of your code base would even realize it! This will be the basis of our solution \u0026ndash; turn Enum into a Class.\nBut wait! It\u0026rsquo;s not so straightforward. Enums can also be referred directly, like Colour.RED. We do not want to meddle with existing usages of Colour.RED in our code.\nStep 1: Change enum to class When you change the enum to class, your IDE should instantly throw up an error. This is because Enums are compile time constructs which are being referred in other parts of you application. But not to worry!\nStep 2: Create constants of existing Colours To keep the usages of Colour.RED same, we would need to create constants for all the colours defined in the enum (now class).\npublic final class Colour { public static final Colour RED = new Colour(255, 0, 0); public static final Colour GREEN = new Colour(0, 255, 0); public static final Colour BLUE = new Colour(0, 0, 255); private final int r, g, b; private Colour(int r, int g, int b) { this.r = r; this.g = g; this.b = b; } // getters and toString() } We also do not want the objects of Colour to be created outside the class. If we do not do this, we are essentially allowing anyone to create Colour objects, and defeats the purpose of mimicing the enum. Thus, we would mark the constructor as private.\nCongrats! The IDE should stop raising an error now (inside the Colour class atleast). The above refactoring makes sure that you can still refer to Colour.RED as earlier. Also, now that we made the variables of r, g, and b as private final as we do not want them to change after object creation.\nStep 3: Implement other Enum methods like values() and valueOf() We know that methods like values() and valueOf() are used quite often with enums. To ensure that these usages do not break, we would need to \u0026ldquo;mimic\u0026rdquo; these methods. How can we do that?\nNote the return types of values() and valueOf().\nvalueOf(String) returns in instance of Colour defined by the name provided as a parameter. values() returns an array of Colour, i.e. Colour[] Let us start with the valueOf() method, and it will lead us to the solution of values()\nAs we know, the valueOf() accepts a String as an argument, and returns an instance of Colour. What can we use to preserve the mapping between a String and Colour? A Map!! We can use a HashMap or ConcurrentHashMap for this.\nUpdate 17-07-2021: DO NOT USE HashMap or ConcurrentHashMap, instead use LinkedHashMap, for reasons that will be explained later in the article.\nNote that we currently have no way of knowing what colour an instance is. Of course, we have a constant declared as\npublic static final Colour RED = new Colour(255, 0, 0); but even if we load it into a map, how would we know if the object is for Colour.RED or Colour.GREEN? Is there a way we can get the \u0026ldquo;text\u0026rdquo;/\u0026ldquo;name\u0026rdquo; of the variable as a String? Not directly, no.\nEnter: Java Reflection\nIt allows an executing Java program to examine or \u0026ldquo;introspect\u0026rdquo; upon itself, and manipulate internal properties of the program. For example, it\u0026rsquo;s possible for a Java class to obtain the names of all its members and display them.\nWe can use this! Let us first define a Map of type Map\u0026lt;String, Colour\u0026gt; as a HashMap or ConcurrentHashMap. We will then use Java Reflection to load up the values inside the Map through a static block.\npublic final class Colour { public static final Colour RED = new Colour(255, 0, 0); public static final Colour GREEN = new Colour(0, 255, 0); public static final Colour BLUE = new Colour(0, 0, 255); private static final Map\u0026lt;String, Colour\u0026gt; map = new LinkedHashMap\u0026lt;\u0026gt;(); static { loadClassData(); } private static void loadClassData() { Arrays.stream(Colour.class.getDeclaredFields()) .filter(declaredField -\u0026gt; declaredField.getType() == Colour.class) .forEach(Colour::putInMap); } private static void putInMap(Field declaredField) { try { map.putIfAbsent(declaredField.getName(), (Colour) declaredField.get(null)); } catch (IllegalAccessException e) { System.err.println(\u0026#34;Could not initialize Colour Map value: \u0026#34; + declaredField.getName() + \u0026#34; \u0026#34; + e); } } private final int r, g, b; private Colour(int r, int g, int b) { this.r = r; this.g = g; this.b = b; } // getters and toString() } The above codeblock uses Java Streams to load up the map. Let us go through what it does.\nThe Colour.class.getDeclaredFields() fetches all the fields declared inside the Colour class. For each of the field returned, we only want the fields of type Colour. (The previous statement would also return Map\u0026lt;String, Colour\u0026gt;) For each of the fields of Colour, we would call the putInMap() method. The putInMap() takes a parameter of type Field, and loads the data in the map. The variable name is obtained by declaredField.getName(), and the actual object is returned by declaredField.get(null) If you do not understand the above Stream based code, or you\u0026rsquo;re just working with Java 7 and lower, you can use the following:\nprivate static void loadClassData() { for (Field declaredField : Colour.class.getDeclaredFields()) { if (declaredField.getType() == Colour.class) { putInMap(declaredField); } } } We have the data in the map! We can now just implement the valueOf() method as follows:\npublic static Colour valueOf(String name) { Colour colour = map.get(name); if (colour == null) { throw new IllegalArgumentException(\u0026#34;No Colour by the name \u0026#34; + name + \u0026#34; found\u0026#34;); } return colour; } Note that in Enums, the valueOf() returns an IllegalArgumentException if no value is found within the enum. Similarly, we will ensure that our implementation also returns the same exception.\nThe usage of Map enables us to easily implement the values() method. We can implement it by using the map.values() method.\npublic static Colour[] values() { return map.values().toArray(Colour[]::new).clone(); } Update 14-07-2021: The map does not have ordered values, so we need to sort it! The tests have been updated in the later sections.\nUpdate 17-07-2021: Since the values() method produces an array in the order in which the Enum values are defined, we need to preserve the order in the Map as well. This is why we need to use a LinkedHashMap, rather than another Map implementation.\nEvery time the values() is called, it returns the clone of the array values in the map.\nStep 4: Load data from the Database However, the purpose of having a dynamic Enum is still not achieved. We want the values of the colour to be loaded up from a database. The problem now seems trivial. Similar to the way we loaded up the class data inside the map, we must also fetch the data from the database and load it. This needs to take place in the static block as well.\nHowever, in this case we cannot use Java Reflection to get the variable name, simply because there isn\u0026rsquo;t any static variable we can refer to.\nThus, we must add another field into the class named colourName.\npublic final class Colour { public static final Colour RED = new Colour(\u0026#34;RED\u0026#34;, 255, 0, 0); public static final Colour GREEN = new Colour(\u0026#34;GREEN\u0026#34;, 0, 255, 0); public static final Colour BLUE = new Colour(\u0026#34;BLUE\u0026#34;, 0, 0, 255); private static final Map\u0026lt;String, Colour\u0026gt; map = new LinkedHashMap\u0026lt;\u0026gt;(); // other implemented methods // new field private final String colourName; private final int r, g, b; private Colour(String colourName, int r, int g, int b) { this.colourName = colourName; this.r = r; this.g = g; this.b = b; } // getters and toString() } Thus, when we load up the data from the database, we would know what key to use for the Map.\nOur static block would now have\nstatic { loadClassData(); loadDataFromDb(); } private static void loadDataFromDb() { List\u0026lt;ColourDB.ColourData\u0026gt; colourData = new ColourDB().getColours(); for (ColourDB.ColourData colourDatum : colourData) { map.putIfAbsent(colourDatum.getColourName(), new Colour(colourDatum)); } } Our ColourDB contains the static class ColourData, which is exactly the same as the Colour POJO. As we cannot create Colour objects, we need another type to put the data in, and get the data from.\nThe ColourDB is like the following:\npublic class ColourDB { public List\u0026lt;ColourData\u0026gt; getColours() { // data from DB } static class ColourData { String colourName; int r; int g; int b; public ColourData(String colourName, int r, int g, int b) { this.colourName = colourName; this.r = r; this.g = g; this.b = b; } // getters } } We can now add another private constructor within Colour that accepts ColourData.\nprivate Colour(ColourDB.ColourData colourDatum) { this.colourName = colourDatum.getColourName(); this.r = colourDatum.getR(); this.g = colourDatum.getG(); this.b = colourDatum.getB(); } Notice that using this method allows you to make Colours dynamic, but prevents you from creating static objects like Colour.RED. If we add the data for the colour \u0026ldquo;BLACK\u0026rdquo; in the DB, we cannot refer to it as Colour.BLACK after this change. We would need to refer to it as Colour.valueOf(\u0026quot;BLACK\u0026quot;), and get the value. This is a trade off required to make it dynamic. However, this allows us to ensure that the existing code is not impacted.\nIf you have a implemented a getter method for colourName, refactor it from getColourName() to name().\nSimilarly, if you use ordinal() method of the enum, ensure that you introduce the ordinal field in the Colour class as well. You would need to store the ordinal field in the DB too.\nYou can also implement the equals() method and change it to compare using == as is done in Enums. One would also need to implement the Comparable interface with the compareTo() method.\nWe will also implement the Serializable interface to enable us to serialize objects. This will ensure we conform to the Enum functionality. Also, Enums cannot be cloned. Hence, we will also implement the clone method and throw CloneNotSupportedException.\nThe updated code would look like the following:\npublic final class Colour implements Comparable\u0026lt;Colour\u0026gt;, Serializable { public static final Colour RED = new Colour(\u0026#34;RED\u0026#34;, 255, 0, 0, 0); public static final Colour GREEN = new Colour(\u0026#34;GREEN\u0026#34;, 0, 255, 0, 1); public static final Colour BLUE = new Colour(\u0026#34;BLUE\u0026#34;, 0, 0, 255, 2); private static final Map\u0026lt;String, Colour\u0026gt; map = new LinkedHashMap\u0026lt;\u0026gt;(); static { loadClassData(); loadDataFromDb(); } private static void loadClassData() { Arrays.stream(Colour.class.getDeclaredFields()) .filter(declaredField -\u0026gt; declaredField.getType() == Colour.class) .forEach(Colour::putInMap); } private static void loadDataFromDb() { List\u0026lt;ColourDB.ColourData\u0026gt; colourData = new ColourDB().getColours(); for (ColourDB.ColourData colourDatum : colourData) { map.putIfAbsent(colourDatum.getColourName(), new Colour(colourDatum)); } } public static Colour[] values() { return map.values().toArray(Colour[]::new).clone(); } public static Colour valueOf(String name) { Colour colour = map.get(name); if (colour == null) { throw new IllegalArgumentException(\u0026#34;No Colour by the name \u0026#34; + name + \u0026#34; found\u0026#34;); } return colour; } private final String colourName; private final int r, g, b; private final int ordinal; private Colour(String colourName, int r, int g, int b, int ordinal) { this.colourName = colourName; this.r = r; this.g = g; this.b = b; this.ordinal = ordinal; } private Colour(ColourDB.ColourData colourData) { this.colourName = colourData.getColourName(); this.r = colourData.getR(); this.g = colourData.getG(); this.b = colourData.getB(); this.ordinal = colourData.getOrdinal(); } private static void putInMap(Field declaredField) { try { map.putIfAbsent(declaredField.getName(), (Colour) declaredField.get(null)); } catch (IllegalAccessException e) { System.err.println(\u0026#34;Could not initialize Colour Map value: \u0026#34; + declaredField.getName() + \u0026#34; \u0026#34; + e); } } public String name() { return colourName; } public int ordinal() { return ordinal; } // getters // .. // .. @Override public boolean equals(Object o) { return this == o; } @Override public int hashCode() { return Objects.hash(colourName, r, g, b, ordinal); } @Override public final int compareTo(Colour o) { Colour self = this; return self.ordinal - o.ordinal; } @Override protected Object clone() throws CloneNotSupportedException { throw new CloneNotSupportedException(); } @Override public String toString() { return \u0026#34;Colour{\u0026#34; + \u0026#34;colourName=\u0026#39;\u0026#34; + colourName + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, r=\u0026#34; + r + \u0026#34;, g=\u0026#34; + g + \u0026#34;, b=\u0026#34; + b + \u0026#34;, ordinal=\u0026#34; + ordinal + \u0026#39;}\u0026#39;; } } and ColourDB as\npublic class ColourDB { public List\u0026lt;ColourData\u0026gt; getColours() { // data from DB } static class ColourData { String colourName; int r; int g; int b; int ordinal; public ColourData(String colourName, int r, int g, int b, int ordinal) { this.colourName = colourName; this.r = r; this.g = g; this.b = b; this.ordinal = ordinal; } // getters } } Step 5: Test Ordinarily, this would work. Unless, of course, you actually want to write unit tests for the class.\nHowever, how can we test it? Notice that testing it is almost impossible, unless you have an actual DB. This is because of the following piece of code.\nprivate static void loadDataFromDb() { List\u0026lt;ColourDB.ColourData\u0026gt; colourData = new ColourDB().getColours(); for (ColourDB.ColourData colourDatum : colourData) { map.putIfAbsent(colourDatum.getColourName(), new Colour(colourDatum)); } } Here, the dependency for the Database new ColourDB() is hard-coded inside the class. Testing would require an actual Database connection. We would want to Mock it during testing. If we were using a DI framework like Spring, we could have injected it. However, using pure Java code would require some more refactoring.\nFirst, we need to extract ColourDB into an interface and include the actual implementation as ColourDbImpl.\npublic interface ColourDB { List\u0026lt;ColourData\u0026gt; getColours(); class ColourData { // existing } } public class ColourDBImpl implements ColourDB { @Override public List\u0026lt;ColourData\u0026gt; getColours() { // get from DB } } We will now create a class named DB:\npublic class DB { private static ColourDB COLOUR_DB; public DB(ColourDB colourDB) { COLOUR_DB = colourDB; } public static ColourDB getColourDb() { if (COLOUR_DB == null) { COLOUR_DB = new ColourDBImpl(); } return COLOUR_DB; } public static void setColourDb(ColourDB colourDb) { COLOUR_DB = colourDb; } } We can now replace ColourDB in loadDataFromDb with DB.getColourDb(). The code now looks like\nprivate static void loadDataFromDb() { List\u0026lt;ColourDB.ColourData\u0026gt; colourData = DB.getColourDb().getColours(); for (ColourDB.ColourData colourDatum : colourData) { map.putIfAbsent(colourDatum.getColourName(), new Colour(colourDatum)); } } Now that we have refactored it, we can Mock it successfully.\nYou can see the test class ColourTest as follows\n@TestInstance(TestInstance.Lifecycle.PER_CLASS) class ColourTest { public static final String BLACK = \u0026#34;BLACK\u0026#34;; public static final String WHITE = \u0026#34;WHITE\u0026#34;; public static final String YELLOW = \u0026#34;YELLOW\u0026#34;; public static final String RED = \u0026#34;RED\u0026#34;; @Mock ColourDBImpl colourDB; @InjectMocks DB db; @BeforeAll void setUp() { MockitoAnnotations.openMocks(this); ColourDB.ColourData black = new ColourDB.ColourData(BLACK, 255, 255, 255, 3); ColourDB.ColourData white = new ColourDB.ColourData(WHITE, 0, 0, 0, 4); ColourDB.ColourData yellow = new ColourDB.ColourData(YELLOW, 255, 255, 0, 5); Mockito.when(colourDB.getColours()).thenReturn(List.of(black, white, yellow)); } @Test void test_values() { Colour[] values = Colour.values(); assertEquals(Colour.RED.name(), values[0].name()); assertEquals(Colour.valueOf(YELLOW).name(), values[values.length - 1].name()); assertTrue(Arrays.stream(values).anyMatch(colour -\u0026gt; colour.name().equals(Colour.RED.name()))); assertTrue(Arrays.stream(values).anyMatch(colour -\u0026gt; colour.name().equals(Colour.valueOf(WHITE).name()))); assertEquals(6, values.length); } @Test void test_if_instances_are_same() { assertSame(Colour.RED, Colour.valueOf(RED)); assertSame(Colour.valueOf(RED), Colour.valueOf(RED)); assertEquals(Colour.valueOf(RED), Colour.valueOf(RED)); assertSame(Colour.valueOf(WHITE), Colour.valueOf(WHITE)); assertEquals(Colour.valueOf(WHITE), Colour.valueOf(WHITE)); } @Test void test_ordinal() { assertEquals(0, Colour.RED.ordinal()); // static assertEquals(5, Colour.valueOf(YELLOW).ordinal()); // dynamic } @Test void test_invalid_colour() { String magenta = \u0026#34;MAGENTA\u0026#34;; IllegalArgumentException exception = assertThrows(IllegalArgumentException.class, () -\u0026gt; Colour.valueOf(magenta)); assertEquals(\u0026#34;No Colour by the name \u0026#34; + magenta + \u0026#34; found\u0026#34;, exception.getMessage()); } @Test void test_compareTo() { int red = Colour.RED.compareTo(Colour.valueOf(\u0026#34;WHITE\u0026#34;)); assertTrue(red \u0026lt; 0); int yellow = Colour.valueOf(\u0026#34;YELLOW\u0026#34;).compareTo(Colour.RED); assertTrue(yellow \u0026gt; 0); } @Test void test_name() { assertEquals(\u0026#34;RED\u0026#34;, Colour.RED.name()); assertEquals(\u0026#34;YELLOW\u0026#34;, Colour.valueOf(\u0026#34;YELLOW\u0026#34;).name()); } } You will need to use @BeforeAll with @TestInstance(TestInstance.Lifecycle.PER_CLASS) as the static block is only executed once. Else Mockito will throw an UnnecessaryStubbingException because the Mock would not execute every test.\nStep 6: Serialization! We did not consider what would happen if we serialize the Colour class. Enum constants are serialized differently than ordinary serializable or externalizable objects. Only the name of the field is serialized, and deserialization uses valueOf() method to get the Enum constant back.\nEnums are effectively singletons. However, the singleton property of our class can be broken during deserialization. Thus, we need to ensure that we preserve the singleton property of Colour as well. We can do that by implementing the readResolve1 method. This will ensure that we only receive an instance of the same class as the one that we have already created. We already store the colour name. So when a new object is created, it will still return the already existing objects that we expect.\npublic final class Colour implements Comparable\u0026lt;Colour\u0026gt;, Serializable { // Existing code // // private Object readResolve() { return Colour.valueOf(colourName); } } We can add a test and verify if this will work.\n@Test void test_serialization_deserialization() throws IOException, ClassNotFoundException { serialize(Colour.valueOf(BLACK)); Colour black = deserialize(); assertNotNull(black); assertEquals(Colour.valueOf(BLACK), black); assertSame(Colour.valueOf(BLACK), black); serialize(Colour.RED); Colour red = deserialize(); assertNotNull(red); assertEquals(Colour.valueOf(RED), red); assertSame(Colour.valueOf(RED), red); assertEquals(Colour.RED, red); assertSame(Colour.RED, red); } void serialize(Colour colour) throws IOException { try (FileOutputStream fos = new FileOutputStream(\u0026#34;data.obj\u0026#34;); ObjectOutputStream oos = new ObjectOutputStream(fos)) { oos.writeObject(colour); } } Colour deserialize() throws IOException, ClassNotFoundException { try (FileInputStream fis = new FileInputStream(\u0026#34;data.obj\u0026#34;); ObjectInputStream ois = new ObjectInputStream(fis)) { return (Colour) ois.readObject(); } } It does! :)\nLimitations As you know, this has a limitation that you cannot statically infer Enum constants, except the ones defined inside Colour. The values in DB must be referred through Colour.valueOf(). Moreover, you would need to change any switch-case statements to use the value of the the Constant, instead of static enum types supported by switch-case. An example:\nswitch (Colour.RED.name()) { case \u0026#34;RED\u0026#34; : System.out.println(\u0026#34;RED\u0026#34;); break; default: } I discovered that this is also known as a type-safe enum, which was used before Enum as types were introduced in Java 5. Granted, this a step lower than Enums, but\u0026hellip; you know.\nThe above is a hack though. In an ideal world, you would never have to try and implement these hacks. However, if you find yourself in such a spot, you know what to do. Please, try to refactor and remove this code though.\nYou can find the code for the project on my Github repository: dynamic-enums.\nDone! We have now created a \u0026ldquo;Dynamic Enum\u0026rdquo;! \u0026#x1f60e;\nYou can now rest in peace, and wish/hope that the next developer touching this piece of code does not try to contact you.\nReferences and Reading material:\nJava Magazine tutorial on Enums How to use typesafe enums in Java Beware of Java typesafe enumerations More on typesafe enums Enum Tricks: Dynamic Enums Introduction to Java Serialization Java Serialization Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://darshit.dev/posts/dynamic-enums/","summary":"\u003ch3 id=\"but-can-one-even-make-enums-dynamic\"\u003eBut can one even make Enums dynamic?\u003c/h3\u003e\n\u003cp\u003eEnums, by definition, are static. They are used to \u0026ldquo;predefine\u0026rdquo; constants. I\u0026rsquo;ll let the official \u003ca href=\"https://docs.oracle.com/javase/tutorial/java/javaOO/enum.html\"\u003eOracle Java Tutorial on Enums\u003c/a\u003e to help explain the definition.\u003c/p\u003e","title":"Dynamic Enums"},{"content":"How do you define and use constants in Java?\nMost advice on Internet has the following opinions:\nDeclare public static final for constants in a class Do not use Interfaces for constants The most common way to define a constant is in a class and using public static final. One can then use the constant in another class using ClassName.CONSTANT_NAME. Constants are usually defined in upper cases as a rule, atleast in Java.\nSo if I were to define a constant for the value of Pi(π), it would be something like:\npublic final class Constants { public static final double PI = 3.14; } This can then be used as Constants.PI whenever we want to reference the value of Pi.\nAnother way one can define constants is by the use of interfaces.\npublic interface Constants { double PI = 3.14; } However, this is not recommended by most sources on the internet. Why? Because it is an anti-pattern.\nBut is it really an Anti-pattern? Let\u0026rsquo;s examine the difference by using both the methods.\nCreating a Constants class: package constants; public final class MathConstantsClass { public static final double PI = 3.14; } Creating an interface: package constants; public interface MathConstantsInterface { double PI = 3.14; } Let us define another interface which will help us test both the above methods.\npackage operations; public interface CircleArea { double calculate(double radius); } The above interface would help us define a contract to calculate the area of a circle. As we know, the area of a circle is dependent only on its radius, and thus is reflected in the above interface.\nThe following class provides the implementation of calculating the area of a circle.\nimport constants.MathConstantsClass; import operations.CircleArea; public class MathConstantsClassImplementation implements CircleArea { public double calculate(double radius) { return MathConstantsClass.PI * radius * radius; } } To test the the above code, let us write a Test class using JUnit.\nimport operations.CircleArea; import org.junit.jupiter.api.Test; import static org.junit.jupiter.api.Assertions.*; class MathConstantsClassImplementationTest { @Test void calculate() { CircleArea area = new MathConstantsClassImplementation(); double circleArea = area.calculate(1.0); assertEquals(3.14, circleArea); } } If you run the above piece of test code, the test would pass.\nFor testing how we can use the constants with Interface, let\u0026rsquo;s write another class called MathConstantsInterfaceImplementation.\nimport constants.MathConstantsInterface; import operations.CircleArea; public class MathConstantsInterfaceImplementation implements MathConstantsInterface, CircleArea { public double calculate(double radius) { return PI * radius * radius; } } Similarly a test for the above class is as follows:\nimport operations.CircleArea; import org.junit.jupiter.api.Test; import static org.junit.jupiter.api.Assertions.*; class MathConstantsInterfaceImplementationTest { @Test void calculate() { CircleArea area = new MathConstantsInterfaceImplementation(); double circleArea = area.calculate(1.0); assertEquals(3.14, circleArea); } } The above Test would pass. However, the argument against the implementation is that it is not a good practice as there could be field shadowing, and that will override the original value of the constant within the class.\nIt can be better understood with the following example:\nimport constants.MathConstantsInterface; import operations.CircleArea; public class MathConstantsWithInterfaceImplementationAndConstantShadowing implements MathConstantsInterface, CircleArea { private static final double PI = 200; public double calculate(double radius) { return PI * radius * radius; } } If, by chance, someone overrode the value of PI inside the class, it would lead to an incorrect output. It can be easily verified by the following test.\nimport operations.CircleArea; import org.junit.jupiter.api.Test; import static org.junit.jupiter.api.Assertions.*; class MathConstantsWithInterfaceImplementationAndConstantShadowingTest { @Test void calculate() { CircleArea area = new MathConstantsWithInterfaceImplementationAndConstantShadowing(); double circleArea = area.calculate(1.0); assertEquals(3.14, circleArea); } } The above test fails. The answer returned by calculate() is 200.0 instead of the expected 3.14. Another argument is, using the interface would pollute the namespace and also lead to the value propagated across the subclasses.\nThe above arguments are valid, and hold true.\nHowever, what no one mentions is that you can still directly use the constants from the interface without implementing the interface. Just like the first example where we use MathConstantsClass.PI, we can also use MathConstantsInterface.PI without affecting the namespace and inheritance and shadowing issues.\nThis can also be easily verified:\nimport constants.MathConstantsInterface; import operations.CircleArea; public class MathConstantsInterfaceWithoutImplementation implements CircleArea { public double calculate(double radius) { return MathConstantsInterface.PI * radius * radius; } } Test class:\nimport operations.CircleArea; import org.junit.jupiter.api.Test; import static org.junit.jupiter.api.Assertions.*; class MathConstantsInterfaceWithoutImplementationTest { @Test void calculate() { CircleArea area = new MathConstantsInterfaceWithoutImplementation(); double circleArea = area.calculate(1.0); assertEquals(3.14, circleArea); } } It would make no difference to our way of implementation. Even the number of imports remain same. Moreover, you do not need additional boilerplate of public static final as members in an interface are public static final by default.\npublic static final double PI = 3.14; vs\ndouble PI = 3.14; What would you prefer? Cleaner code, anyone?\nI have seen most constants almost grouped together if they are used throughout the application. You could also suggest that interface should only be used for contracts, and in most cases they are. However, keeping an interface for solely storing constants doesn\u0026rsquo;t seem to be wrong to me either!\nUnless, of course, some developer tries to implement a class which solely contains constants \u0026ndash; which would beget the question \u0026ndash; WHY?\nYou can check out the code at my Github: https://github.com/darshitpp/JavaConstants\nReferences:\nConstants in Java: Patterns and Anti-Patterns ","permalink":"https://darshit.dev/posts/java-constants-interface/","summary":"\u003cp\u003eHow do you define and use constants in Java?\u003c/p\u003e\n\u003cp\u003eMost advice on Internet has the following opinions:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eDeclare \u003ccode\u003epublic static final\u003c/code\u003e for constants in a class\u003c/li\u003e\n\u003cli\u003eDo not use Interfaces for constants\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThe most common way to define a constant is in a class and using \u003ccode\u003epublic static final\u003c/code\u003e. One can then use the constant in another class using \u003ccode\u003eClassName.CONSTANT_NAME\u003c/code\u003e. Constants are usually defined in upper cases as a rule, atleast in Java.\u003c/p\u003e","title":"The Java Constants Interface Anti-Pattern"},{"content":"I wrote this earlier on a Github gist, but putting it here for a consolidated reference.\nWant to change Java Version/JAVA_HOME for Ant builds? Open ~/.antrc file by running vim ~/.antrc Add JAVACMD=\u0026lt;NEW_JAVA_HOME\u0026gt;/bin/java and save The Ant wrapper script for Unix will source (read and evaluate) the file ~/.antrc before it does anything. On Windows, the Ant wrapper batch-file invokes %HOME%\\antrc_pre.bat at the start and %HOME%\\antrc_post.bat at the end. You can use these files, for example, to set/unset environment variables that should only be visible during the execution of Ant.\nThe wrapper scripts use the following environment variables (if set):\nJAVACMD—full path of the Java executable. Use this to invoke a different JVM than JAVA_HOME/bin/java(.exe). ANT_OPTS—command-line arguments that should be passed to the JVM. For example, you can define system properties or set the maximum Java heap size here. ANT_ARGS—Ant command-line arguments. For example, set ANT_ARGS to point to a different logger, include a listener, and to include the -find flag. Note: If you include -find in ANT_ARGS, you should include the name of the build file to find, even if the file is called build.xml. Source: https://ant.apache.org/manual/running.html\n","permalink":"https://darshit.dev/posts/change-java-version-ant/","summary":"\u003cp\u003eI wrote this earlier on a \u003ca href=\"https://gist.github.com/darshitpp/f8017cdb61f4056c100edbf0182a6be0\"\u003eGithub gist\u003c/a\u003e, but putting it here for a consolidated reference.\u003c/p\u003e\n\u003ch2 id=\"want-to-change-java-versionjava_home-for-ant-builds\"\u003eWant to change Java Version/JAVA_HOME for Ant builds?\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eOpen \u003ccode\u003e~/.antrc\u003c/code\u003e file by running \u003ccode\u003evim ~/.antrc\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eAdd \u003ccode\u003eJAVACMD=\u0026lt;NEW_JAVA_HOME\u0026gt;/bin/java\u003c/code\u003e and save\u003c/li\u003e\n\u003c/ol\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe Ant wrapper script for Unix will source (read and evaluate) the file ~/.antrc before it does anything.\nOn Windows, the Ant wrapper batch-file invokes %HOME%\\antrc_pre.bat at the start and %HOME%\\antrc_post.bat at the end.\nYou can use these files, for example, to set/unset environment variables that should only be visible during the execution of Ant.\u003c/p\u003e","title":"How to change Java Version/JAVA_HOME for Ant?"},{"content":"A couple of weeks ago, I was tasked with figuring out a way to enable two way SSL. I am a programmer, and have had only a limited experience with networking concepts like SSL/TLS in my short career. So I turned up blank on how I could make it possible. Moreover, the terminology you\u0026rsquo;d find online is not uniform. From a programming point of view, the term \u0026ldquo;Two way SSL\u0026rdquo; led me to limited results, and I soon realized that other communities have different terminology. For example the \u0026ldquo;Two way SSL\u0026rdquo; is also known as \u0026ldquo;Mutual TLS\u0026rdquo; or \u0026ldquo;mTLS\u0026rdquo; or \u0026ldquo;Client Certificate Authentication\u0026rdquo; in Cloud/DevOps communitites. This makes finding the right resources online more difficult.\nOur services have SSL enabled, but only the usual one \u0026ndash; similar to the one you\u0026rsquo;d find while visiting this website, but this was a unique thing for me as I didn\u0026rsquo;t even know two way SSL existed. I figured out how it works. However, there were more problems with trying to understand how to implement this. Most guides that I found on the internet were very incomplete, and straight away skipped many parts for someone who\u0026rsquo;d be new to this. This is my attempt at explaining what I have learned, and documenting the same for future reference. It will not explain how two way SSL works, but how to make it work. If you need a quick refresher however, I would direct you to this easy to understand article by Cloudflare explaining where and how mTLS is used.\nThis guide is only for Unix like systems like macOS or Linux. Though I tried this on Windows, but could not make it work.\nPrerequisites Nginx sudo privileges on your system Installing and Configuring Nginx Install Install1 nginx using apt command on your Linux system.\nsudo apt update sudo apt install nginx This will install all of Nginx on the path /opt/nginx. All the configuration files we will be editing for two-way SSL would be found within this directory.\nConfigure Nginx to start Before starting up Nginx for use, we need to enable some ports on the firewall that our Nginx can listen incoming connections from.\nsudo ufw app list Output:\nAvailable applications: Nginx Full Nginx HTTP Nginx HTTPS OpenSSH The utility ufw can be used to manage our firewall. Though a knowledge of ufw is not necessary for us, more information can be found here.\nYou can see in the above output that the utility responds us with four profiles. When we installed Nginx, it registered itself with the ufw utility with three profiles.\nNginx HTTP allows Nginx to listen through port 80, for normal HTTP traffic. Nginx HTTPS allows Nginx to listen through port 443, for HTTPS traffic. Nginx Full is a combination of the above both, enabling port 80 and 443 both. We will enable Nginx Full as we have to use our server for SSL, but using normal HTTP connections is not an uncommon use-case either. To enable it, run:\nsudo ufw allow \u0026#39;Nginx Full\u0026#39; You should see the activated profile if you run the below command\nsudo ufw status Output:\nStatus: active To Action From -- ------ ---- OpenSSH ALLOW Anywhere Nginx Full ALLOW Anywhere OpenSSH (v6) ALLOW Anywhere (v6) Nginx Full (v6) ALLOW Anywhere (v6) The Nginx service should already be up and running now. You can check by executing\nsystemctl status nginx Output:\n● nginx.service - A high performance web server and a reverse proxy server Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) Active: active (running) since Fri 2018-04-20 16:08:19 UTC; 3 days ago Docs: man:nginx(8) Main PID: 2369 (nginx) Tasks: 2 (limit: 1153) CGroup: /system.slice/nginx.service ├─2369 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; └─2380 nginx: worker process Creating Certificates Terminology Certificate Authority (CA): This is an Organization which provides you a Certificate (the .crt file). In reality, anyone (including yourself) can be the CA which issues certificates Certificate Signing Request (CSR .csr): An \u0026ldquo;input form\u0026rdquo; with details (like Name, Organization, Address, etc.) filled by the requester of the certificate which is submitted to the CA Private Key (.key): The private key file used by the CA in conjunction with CSR to sign and generate the certificates Certificate (.crt): The certificate generated by the CA Self Signed Certificate: Consider yourself as a Certificate Authority (CA) and generate the .crt files. Now that we know the terminology, it would be easier to proceed with generating the certificates. The following part of the tutorial requires root/superuser privileges, so switch to the super user using the sudo su command.\nCreate a directory called certs under the root of the file-system which will hold all the certificates and related files.\n# Create directory mkdir /certs # Change directory to /certs cd /certs # Verify the present working directory pwd Output:\n/certs In this tutorial, we would be designating ourselves as a Certificate Authority, and then self-sign and generate the certificates.\nGenerate Certificate Authority (CA) files We would be first generating a CA key, which would be the basis for all further certificate generation.\nopenssl genrsa -des3 -out ca.key 4096 Output:\nGenerating RSA private key, 4096 bit long modulus (2 primes) .............................................................++++ ....................................................................................................................................................................................++++ e is 65537 (0x010001) Enter pass phrase for ca.key:\u0026lt;passphrase\u0026gt; Verifying - Enter pass phrase for ca.key:\u0026lt;passphrase\u0026gt; Command options:\ngenrsa: generate RSA private key -des3: encrypts the output key using des3 encryption -out: specifying the output key file 4096: size of private key in bits This generates a file named ca.key in the current directory. You would have to provide a password/passphrase for the key. For the purposes of this tutorial, I\u0026rsquo;ll be using the same passphrase whenever required.\n\u0026lt;passphrase\u0026gt; = root\nThe next step is the generation of ca.crt\nopenssl req -new -x509 -days 3650 -key ca.key -out ca.crt Output:\nEnter pass phrase for ca.key:\u0026lt;passphrase\u0026gt; Command options:\nreq: used for creating certificate requests -new: generates new certificate request -x509: outputs a new self-signed certificate instead of a certificate request -days 3650: validity of certificate (in this case, 10 years/3650 days) -key: RSA key to be used for generating the certificate -out: output file for the certificate Once you enter the passphrase (which is the same as we put in the previous step), it\u0026rsquo;ll ask you to provide more information for the self-signed certificate.\nYou are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [AU]: State or Province Name (full name) [Some-State]: Locality Name (eg, city) []: Organization Name (eg, company) [Internet Widgits Pty Ltd]:CertAuth Organizational Unit Name (eg, section) []: Common Name (e.g. server FQDN or YOUR name) []: Email Address []: Note the Organization Name parameter is named as CertAuth for this example. This is because we are a CA and CAs should ideally be independent to enable other parties to trust other parties and establish a chain of trust.\nA PEM file certificate would also be needed. This file is way of encoding the certificates.2 To create a PEM file, simply do the following:\ncat ca.key \u0026gt; ca.pem cat ca.key \u0026gt;\u0026gt; ca.pem The ca.key would be something like\n-----BEGIN RSA PRIVATE KEY----- Proc-Type: 4,ENCRYPTED DEK-Info: DES-EDE3-CBC,0E2D38C130456B75 3+0Em2EKRkmCCu79bR7E2uFy/G1huIGEGsItwDf0C70Hf2bmUUDYazK/CPZxZCut PDximngoGaLSdLQ2HWGjjCe59pJxxZknxHu9QVy3mIWLixAZWevDUnoK1q+Wqy0M -----END RSA PRIVATE KEY----- -----BEGIN CERTIFICATE----- MIIFSzCCAzOgAwIBAgIUeawaQJUIAPKOKhrIJDjMVCYVx4MwDQYJKoZIhvcNAQEL BQAwNTELMAkGA1UEBhMCQVUxEzARBgNVBAgMClNvbWUtU3RhdGUxETAPBgNVBAoM -----END CERTIFICATE----- Generating Client/User Certificates At this point, we have three files in the certs directory.\nca.key ca.crt ca.pem We now would be generating client/user certificates. The command to generate the user.key is similar to the one used to create the ca.key\nopenssl genrsa -des3 -out user.key 4096 Output:\nGenerating RSA private key, 4096 bit long modulus (2 primes) .....................................................................................................................................................++++ .......................++++ e is 65537 (0x010001) Enter pass phrase for user.key: Verifying - Enter pass phrase for user.key: As mentioned earlier, the passphrase to be used for user.key is still the same.\nThe client/user certificate aren\u0026rsquo;t supposed to be self-signed, and we would need to generate a CSR. It means the signing is to be done by a CA(even though in this case, we own the CA!). The way to do this is\nopenssl req -new -key user.key -out user.csr Output:\nEnter pass phrase for user.key:\u0026lt;passphrase\u0026gt; You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [AU]: State or Province Name (full name) [Some-State]: Locality Name (eg, city) []: Organization Name (eg, company) [Internet Widgits Pty Ltd]:User Organizational Unit Name (eg, section) []: Common Name (e.g. server FQDN or YOUR name) []: Email Address []: Please enter the following \u0026#39;extra\u0026#39; attributes to be sent with your certificate request A challenge password []: An optional company name []: The Organization Name would be User as this certificate is for a Client/User. DO NOT keep it the same as the one for CA.\nThe next step would be to create a User Certificate from the User CSR.\nopenssl x509 -req -days 365 -in user.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out user.crt Output:\nSignature ok subject=C = AU, ST = Some-State, O = User Getting CA Private Key Enter pass phrase for ca.key:\u0026lt;passphrase\u0026gt; Command options:\nx509: standard format for public key certificates -CA: the CA certificate -CAkey: the key to generate the certificate from -set_serial 01: the serial version of the certificate to be generated. The user certificate can be regenerated by incrementing the serial number from the same user.csr after 365 days when it expires. You can see that it displays data from the CSR, and then uses the CA key to generate user.crt.\nTo enable us to use the certificate from a web browser, we would need to create the certificate in the PFX file format.\nopenssl pkcs12 -export -out user.pfx -inkey user.key -in user.crt -certfile ca.crt Output:\nEnter pass phrase for user.key:\u0026lt;passphrase\u0026gt; Enter Export Password:\u0026lt;passphrase\u0026gt; Verifying - Enter Export Password:\u0026lt;passphrase\u0026gt; You can verify if the generated certificate can be decrypted using the CA certificate by the following command\nopenssl verify -verbose -CAfile ca.crt user.crt Output:\nuser.crt: OK The files that we currently have in the directory are\nca.key ca.crt ca.pem user.key user.csr user.crt user.pfx Generating Server Certificates This is similar to generating the User certificates, with the following commands\nGenerate the Server key. For server certificates, the standard naming convention seems to be \u0026lt;website-domain-name\u0026gt;.\u0026lt;key\u0026gt;\nopenssl genrsa -out nginx.mssl.com.key 4096 Output:\nGenerating RSA private key, 4096 bit long modulus (2 primes) .....................................++++ .........................++++ e is 65537 (0x010001) Use the above generated key to generate a CSR.\nopenssl req -new -key nginx.mssl.com.key -out nginx.mssl.com.csr Output:\nYou are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [AU]: State or Province Name (full name) [Some-State]: Locality Name (eg, city) []: Organization Name (eg, company) [Internet Widgits Pty Ltd]:Server Organizational Unit Name (eg, section) []: Common Name (e.g. server FQDN or YOUR name) []:nginx.mssl.com Email Address []: Please enter the following \u0026#39;extra\u0026#39; attributes to be sent with your certificate request A challenge password []: An optional company name []: Make sure to put the Organization Name as Server and Common Name (which is the website name) as nginx.mssl.com\nWe can now use the CSR along with the CA files to generate the CRT for our server.\nopenssl x509 -req -days 365 -sha256 -in nginx.mssl.com.csr -CA ca.crt -CAkey ca.key -set_serial 1 -out nginx.mssl.com.crt Output:\nSignature ok subject=C = AU, ST = Some-State, O = Server, CN = nginx.mssl.com Getting CA Private Key Enter pass phrase for ca.key:\u0026lt;passphrase\u0026gt; All the certificates are now ready for our use!\nca.key ca.crt ca.pem user.key user.csr user.crt user.pfx nginx.mssl.com.key nginx.mssl.com.csr nginx.mssl.com.crt Setting up our \u0026ldquo;Website\u0026rdquo; with Nginx Of course, we aren\u0026rsquo;t setting up a real website. But we do want to make our SSL authentication work on the domain nginx.mssl.com. We can do this by a little \u0026ldquo;hack\u0026rdquo; by changing our /etc/hosts file.\nFire up a new shell, and use\nsudo vim /etc/hosts Add the following line to the file and save.\n127.0.0.1 nginx.mssl.com This will enable your local machine to resolve the domain nginx.mssl.com to your locahost.\nThe website will not work at the moment \u0026ndash; you\u0026rsquo;d have to specify the sources/web pages it needs to serve when requested.\nCreate a file index.html on the directory path /usr/share/nginx/mssl with the contents:\n\u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!-mutual ssl test\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; If the TLS handshake is successful, the web server should serve the file created above.\nConfiguring the Nginx server to enable two way SSL All our certificates are at root in /certs directory. For simplicity, we would be copying the certificates to /etc/nginx/certs directory.\ncp -r /certs /etc/nginx/certs Also ensure that the certificates can be used by nginx service by providing them the access\nchmod 777 -R certs/ We would not be fiddling with the default nginx configuration which is present in the nginx.conf file. Instead, we would be creating a new file called proxy.conf using in the /etc/nginx/sites-available directory.\nCreate the file proxy.conf using the command\ncd /etc/nginx/sites-available touch proxy.conf Enter the contents as the following (Notice the comments have more explanation):\nserver { # Listen on port 443 for HTTPS connections listen 443; # Turn SSL on ssl on; # Name of the server/website server_name nginx.mssl.com; # See https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_ssl_server_name proxy_ssl_server_name on; # This is the server SSL certificate ssl_certificate /etc/nginx/certs/nginx.mssl.com.crt; # This is the server certificate key ssl_certificate_key /etc/nginx/certs/nginx.mssl.com.key; # Important: # This is the CA cert against which the client/user will be validated # In our case since the Server and the Client certificate is # generated from the same CA, we use the ca.crt # But in actual production, the Client certificate might be # created from a different CA ssl_client_certificate /etc/nginx/certs/ca.crt; # Enables mutual TLS/two way SSL to verify the client ssl_verify_client on; # Number of intermediate certificates to verify. Good explanation of # certificate chaining can be found at # https://cheapsslsecurity.com/p/what-is-ssl-certificate-chain/ ssl_verify_depth 2; # Any error during the connection can be found on the following path error_log /var/log/nginx/error.log debug; ssl_prefer_server_ciphers on; ssl_protocols TLSv1.1 TLSv1.2; ssl_ciphers \u0026#39;ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:ECDHE-RSA-RC4-SHA:ECDHE-ECDSA-RC4-SHA:RC4-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!3DES:!MD5:!PSK\u0026#39;; keepalive_timeout 10; ssl_session_timeout 5m; # Matches the \u0026#34;root\u0026#34; of the website # If TLS handshake is successful, the request is routed to this block location / { # path from which the website is served from root /usr/share/nginx/mssl; # index file name index index.html index.htm; } } Nginx has a good Beginner\u0026rsquo;s Guide to Nginx.\nTo enable Nginx to use the above configuration, we also have to link the same in the /etc/nginx/sites-enabled directory.\nTo accomplish this, use\nln -s /etc/nginx/sites-available/proxy.conf /etc/nginx/sites-enabled/proxy.conf This creates a symbolic link into /etc/nginx/sites-enabled/proxy.conf from /etc/nginx/sites-available/proxy.conf. Consider it as you having many server configurations in the sites-available, but only what you chose to \u0026ldquo;enable\u0026rdquo; in the sites-enabled will be active.\nWe now just have to restart the Nginx for the configuration to be active!\nsystemctl restart nginx I\u0026rsquo;ll be using Postman to test our changes. However, you\u0026rsquo;ll need to configure Postman to send the Client Certificates with the request3.\nTo configure the Certificates, navigate to Settings -\u0026gt; Certificates Tab.\nThere will be a section to add the CA Certificate named CA Certificates, and this certificate should be a PEM file. Select the ca.pem from /etc/nginx/certs. A mistake would be to select the file from the root directory /certs but this will not work as Postman wouldn\u0026rsquo;t be able to access the file.\nThere would be another section below for Client Certificates. Click on Add Certificate, and put the details as the following:\nHost: nginx.mssl.com CRT File: /etc/nginx/certs/user.crt KEY File: /etc/nginx/certs/user.key PFX File: /etc/nginx/certs/user.pfx Passphrase: \u0026lt;passphrase\u0026gt; Now try to fire a GET request to the domain https://nginx.mssl.com. If everything was configured successfully, you\u0026rsquo;ll get the following response:\n\u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!-mutual ssl test\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; If there\u0026rsquo;s an error in the configuration, you\u0026rsquo;ll get the following error response:\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;400 No required SSL certificate was sent\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body bgcolor=\u0026#34;white\u0026#34;\u0026gt; \u0026lt;center\u0026gt; \u0026lt;h1\u0026gt;400 Bad Request\u0026lt;/h1\u0026gt; \u0026lt;/center\u0026gt; \u0026lt;center\u0026gt;No required SSL certificate was sent\u0026lt;/center\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;center\u0026gt;nginx/1.14.0 (Ubuntu)\u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Hope this post was of some help!!\nReference:\nThis article is good for the demo part. The post Client Certificate Auth With Nginx was instrumental in explaining the ssl_client_certificate directive and how to use it. This post is as close to perfection as it gets regarding the steps for generating Certificates, but I couldn\u0026rsquo;t manage to make it work fully with Nginx. (Especially because it skips the demo part + it could be a little more descriptive with generation of the certificates) This article is good, but still unclear for someone starting out. I used this article to actually learn about generating the certificates especially because it provides easy commands and decent explanation. The main resource for installing Nginx is this tutorial by DigitalOcean. All the relevant steps have been described in my article.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMore info here\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nClient Certificates: Postman Learning Center\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://darshit.dev/posts/two-way-ssl-nginx/","summary":"\u003cp\u003eA couple of weeks ago, I was tasked with figuring out a way to enable two way SSL. I am a programmer, and have had only a limited experience with networking concepts like SSL/TLS in my short career. So I turned up blank on how I could make it possible. Moreover, the terminology you\u0026rsquo;d find online is not uniform. From a programming point of view, the term \u0026ldquo;Two way SSL\u0026rdquo; led me to limited  results, and I soon realized that other communities have different terminology. For example the \u0026ldquo;Two way SSL\u0026rdquo; is also known as \u0026ldquo;Mutual TLS\u0026rdquo; or \u0026ldquo;mTLS\u0026rdquo; or \u0026ldquo;Client Certificate Authentication\u0026rdquo; in Cloud/DevOps communitites. This makes finding the right resources online more difficult.\u003c/p\u003e","title":"How To Implement Two Way SSL With Nginx"},{"content":"Yes, you read that right.\nTo give you some context, some time ago, our (my org\u0026rsquo;s) Redis usage was un-tracked \u0026ndash; meaning we didn\u0026rsquo;t know why our Redis memory was being occupied as much as it was. Our 2.5GB of Redis ElastiCache was almost close to being full, and if it somehow reached its limit, our system would start to fail. Though there were fallbacks in place, Redis could turn out to be a bottle-neck.\nIn this post, I would try to explain how we reduced the storage occupied by the data by more than 50%. This would also kind of be a step by step guide from the basics, so if you\u0026rsquo;re just interested in how Redis is being used, just skip the and go to the Optimization section.\nBasic Setup I would be using the latest version of Spring Boot from https://start.spring.io. Firstly, select our two of our main dependencies - Spring Boot Web and Spring Data Reactive Redis.\nYou would find these in the pom.xml file when you download the starter project.\nThe Spring Boot Web is for building basic web applications with Spring Boot, whereas Spring Data Reactive Redis would be used for connecting and using Redis inside the application. At its core, the Redis dependency by default uses the Lettuce Redis client, and is supported by the latest versions of Spring Boot.\nNote that I\u0026rsquo;m going to skip the installation of Redis, as there are other guides available for every operating system. You do need the Redis Server to be started for our application to work successfully.\nAfter downloading the basic application, you\u0026rsquo;ll need to extract and open it in your favourite IDE (my favourite one is IntelliJ IDEA).\nIn my case the project name is redis-util, and you\u0026rsquo;ll find my \u0026ldquo;base packages\u0026rdquo; to be named com.darshitpp.redis.redisutil. This base package would have a class called RedisUtilApplication, which in my case has the following configuration.\n@SpringBootApplication @ComponentScan(basePackages = {\u0026#34;com.darshitpp.redis.redisutil\u0026#34;}) public class RedisUtilApplication { public static void main(String[] args) { SpringApplication.run(RedisUtilApplication.class, args); } } I have manually added the @ComponentScan annotation to specify a top-level package name under where Spring should look for defined Beans/Configurations.\nTo connect to Redis, I create a configuration class called LettuceRedisConfiguration, under a new package named configuration(note that this should be under the basePackages path defined above.\nYou could define the configuration in the RedisUtilApplication class itself, but I want this to be as \u0026ldquo;production-ready\u0026rdquo; as possible. Thus, it\u0026rsquo;s a good practice to separate out your different parts of application.\nMy configuration class is\n@Configuration public class LettuceRedisConfiguration { @Bean public LettuceConnectionFactory redisConnectionFactory() { return new LettuceConnectionFactory(new RedisStandaloneConfiguration(\u0026#34;localhost\u0026#34;, 6379)); } } It is a very simple class, which has the configuration of which URL to connect to for Redis. In my case, it is localhost, but in most production apps, it would be an external Redis server. Port 6379 is the default port on which the Redis server starts. This Bean would return us a \u0026ldquo;factory\u0026rdquo; of Redis connections. Think of this as something which would allow you to connect to Redis when required.\nAt this point, my package structure looks like:\n-\u0026gt;src -\u0026gt;main -\u0026gt;java -\u0026gt;com.darshitpp.redis.redisutil -\u0026gt;configuration Now that we know how to connect to a Redis server, we need to figure out what data we need to store in Redis. In our case, we would be storing User data. This is the \u0026ldquo;domain model\u0026rdquo; of our application (domain model could be translated to a table in a Database, but we don\u0026rsquo;t have a table in our scenario). This User is stored in a package called domain.\nThe User would have three fields, namely, firstName, lastName, and birthday.\nBefore storing the objects in Redis, it is a good idea to identify how you will store the data so that it\u0026rsquo;s efficient to fetch it back. What that means is Redis being a simple Key-Value store, you would need to identify the Key you would be storing the Value with. In our case, I am choosing firstName as the key. The data would be stored in a hash, so the hashKey that we select would be the lastName and the value mapped to the hashKey is the User object.\nThis is because Hashes in Redis have the following structure:\nkey1 --- hashKey1 === value1 --- hashKey2 === value2 --- hashKey3 === value3 key2 --- hashKey4 === value4 --- hashKey5 === value5 . . . You could also imagine it as a tree with the top level nodes being the Keys, the immediate next level to be hashKeys, and the leaf nodes to be the values. To access value2, you would need to have key1 and hashKey2.\nOur example is a bit incorrect, as a User could have same key=firstName and hashKey=lastName as another user, and Redis will overwrite value. However, for brevity, we will assume there are unique Users using our application.\nWe would now be creating a controller class called NormalController which would act as an entry point for our API. We have named it NormalController for reasons that will be clear further in this article.\n@RestController @RequestMapping(\u0026#34;/normal\u0026#34;) public class NormalController { private final NormalService normalService; @Autowired public NormalController(NormalService normalService) { this.normalService = normalService; } @GetMapping(\u0026#34;/get\u0026#34;) public User get(@RequestParam(\u0026#34;firstName\u0026#34;) String firstName, @RequestParam(\u0026#34;lastName\u0026#34;) String lastName) { return normalService.get(firstName, lastName); } @PostMapping(\u0026#34;/insert\u0026#34;) public void insert(@RequestBody User user) { normalService.put(user); } @PostMapping(\u0026#34;/delete\u0026#34;) public void delete(@RequestParam(\u0026#34;firstName\u0026#34;) String firstName) { normalService.delete(firstName); } } NormalController also has a service named NormalService which is Autowired. The class should be defined in a new packaged named controller after which the package structure would look like\n-\u0026gt;src -\u0026gt;main -\u0026gt;java -\u0026gt;com.darshitpp.redis.redisutil -\u0026gt;configuration -\u0026gt;domain -\u0026gt;controller Our basic operations would be simple CRUD like operations which NormalService implements using a custom Operations interface.\npublic interface Operations { User get(String firstName, String lastName); void put(User user); void delete(String firstName); } To use Lettuce in our application, we need to do a couple of more things though. Just like to access JDBC, there\u0026rsquo;s a provision for a JdbcTemplate, you must similarly use a RedisTemplate to operate on Redis. We must also define in what format will Redis store the data inside it. By default, it stores data as a String. However, know that you\u0026rsquo;ll be storing User in Redis, and in order to facilitate the storage and fetch from Redis, you would need a way through which Redis will be able to identify and convert it back to the appropriate type of data you want.\nThink of this as talking with someone who doesn\u0026rsquo;t know the same language as you do. If you want to communicate with someone who only speaks Spanish, you would need to find a translator who would convert English into Spanish for you. This process of conversion and recovery is known as Serialization and Deserialization.\nEnglish to Spanish = Serialization Spanish to English = Deserialization\nThus, we need a translator or a Serializer in our case too. We would be using Jackson for this process. Jackson is a nifty library which Spring Boot supports out-of-the-box to handle Json.\nWe would need to create a Serializer which implements RedisSerializer for our purposes. In our case, I have created a class JsonRedisSerializer inside a new package called serializer.\nclass JsonRedisSerializer\u0026lt;T\u0026gt; implements RedisSerializer\u0026lt;T\u0026gt; { public static final Charset DEFAULT_CHARSET; private final JavaType javaType; private ObjectMapper objectMapper = new ObjectMapper() .registerModules(new Jdk8Module(), new JavaTimeModule(), new ParameterNamesModule(JsonCreator.Mode.PROPERTIES)) .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, true) .configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false) .configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false) .setSerializationInclusion(JsonInclude.Include.NON_NULL); public JsonRedisSerializer(Class\u0026lt;T\u0026gt; type) { this.javaType = JavaTypeHandler.getJavaType(type); } public T deserialize(@Nullable byte[] bytes) throws SerializationException { if (bytes == null || bytes.length == 0) { return null; } else { try { return this.objectMapper.readValue(bytes, 0, bytes.length, this.javaType); } catch (Exception ex) { throw new SerializationException(\u0026#34;Could not read JSON: \u0026#34; + ex.getMessage(), ex); } } } public byte[] serialize(@Nullable Object value) throws SerializationException { if (value == null) { return new byte[0]; } else { try { return this.objectMapper.writeValueAsBytes(value); } catch (Exception ex) { throw new SerializationException(\u0026#34;Could not write JSON: \u0026#34; + ex.getMessage(), ex); } } } static { DEFAULT_CHARSET = StandardCharsets.UTF_8; } } As you can see, it has two methods called serialize and deserialize. Each of these methods use the Jackson\u0026rsquo;s ObjectMapper for conversion.\nThere is also a class named JavaTypeHandler which helps you get the Type of the object you\u0026rsquo;re trying to serialize.\nfinal class JavaTypeHandler { static \u0026lt;T\u0026gt; JavaType getJavaType(Class\u0026lt;T\u0026gt; clazz) { return TypeFactory.defaultInstance().constructType(clazz); } } Consequently, we would also need a class which returns us a RedisTemplate which utilizes this serializer. I would name this class RedisSerializationBuilder.\npublic final class RedisSerializationBuilder { public static \u0026lt;T\u0026gt; RedisTemplate\u0026lt;String, T\u0026gt; getNormalRedisTemplate(final LettuceConnectionFactory factory, final Class\u0026lt;T\u0026gt; clazz) { JsonRedisSerializer\u0026lt;T\u0026gt; jsonRedisSerializer = new JsonRedisSerializer\u0026lt;\u0026gt;(clazz); RedisTemplate\u0026lt;String, T\u0026gt; redisTemplate = new RedisTemplate\u0026lt;\u0026gt;(); redisTemplate.setConnectionFactory(factory); redisTemplate.setDefaultSerializer(RedisSerializer.json()); redisTemplate.setKeySerializer(RedisSerializer.string()); redisTemplate.setValueSerializer(RedisSerializer.string()); redisTemplate.setHashKeySerializer(RedisSerializer.string()); redisTemplate.setHashValueSerializer(jsonRedisSerializer); redisTemplate.afterPropertiesSet(); return redisTemplate; } } Notice that the above method will return you a template specific to a particular domain model(in our case, the User) using Generics. It also specifies what connection factory is to be used, what should be the default key/value/hashKey/hashValue serializers.\nConsequently, the NormalService looks like\n@Service public class NormalService implements Operations{ private final RedisTemplate\u0026lt;String, User\u0026gt; redisTemplate; private final HashOperations\u0026lt;String, String, User\u0026gt; hashOperations; public NormalService(LettuceConnectionFactory redisConnectionFactory) { this.redisTemplate = RedisSerializationBuilder.getNormalRedisTemplate(redisConnectionFactory, User.class); this.hashOperations = this.redisTemplate.opsForHash(); } @Override public User get(String firstName, String lastName) { return hashOperations.get(firstName, lastName); } @Override public void put(User user) { hashOperations.put(user.getFirstName(), user.getLastName(), user); } @Override public void delete(String firstName) { hashOperations.delete(firstName); } } I then inserted a User, using the POST method, and URL: localhost:8080/normalService/insert Request Body:\n{ \u0026#34;firstName\u0026#34;: \u0026#34;Priscilla\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Haymes\u0026#34;, \u0026#34;birthday\u0026#34;: \u0026#34;2020-04-12T11:15:00Z\u0026#34; } If I then run this application for 100 Users, I find the following stats for the memory usage in Redis (I used the memory stats command using the redis-cli)\n21) \u0026#34;keys.count\u0026#34; 22) (integer) 100 23) \u0026#34;keys.bytes-per-key\u0026#34; 24) (integer) 1044 25) \u0026#34;dataset.bytes\u0026#34; 26) (integer) 32840 Using the hgetall command for a key gives me\n127.0.0.1:6379\u0026gt;hgetall \u0026#34;Priscilla\u0026#34; 1) \u0026#34;Haymes\u0026#34; 2) \u0026#34;{\\\u0026#34;firstName\\\u0026#34;:\\\u0026#34;Priscilla\\\u0026#34;,\\\u0026#34;lastName\\\u0026#34;:\\\u0026#34;Haymes\\\u0026#34;,\\\u0026#34;birthday\\\u0026#34;:1586690100000}\u0026#34; Notice that 2) gives us the actual type of data stored in Redis -\u0026gt; Json!\nOur basic structure for further optimizations is in place! Yay!\nOptimization MessagePack is here to the rescue! As I said, you\u0026rsquo;d need a \u0026ldquo;transalation\u0026rdquo; mechanism. What if the translator is an expert, and converts your English into Spanish in as few words as possible? MessagePack is the same!\nYou would need to add two more dependencies in your pom.xml file.\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.msgpack\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;msgpack-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.8.20\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.msgpack\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jackson-dataformat-msgpack\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.8.20\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; We create a controller called MsgPackController and a service called MsgPackService almost similar to NormalController and NormalService. We would create a MsgPackSerializer to serialize using MessagePack.\nclass MsgPackRedisSerializer\u0026lt;T\u0026gt; implements RedisSerializer\u0026lt;T\u0026gt; { public static final Charset DEFAULT_CHARSET; private final JavaType javaType; private ObjectMapper objectMapper = new ObjectMapper(new MessagePackFactory()) .registerModules(new Jdk8Module(), new JavaTimeModule()) .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, true) .configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false) .configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false) .setSerializationInclusion(JsonInclude.Include.NON_NULL); public MsgPackRedisSerializer(Class\u0026lt;T\u0026gt; type) { this.javaType = JavaTypeHandler.getJavaType(type); } public T deserialize(@Nullable byte[] bytes) throws SerializationException { if (bytes == null || bytes.length == 0) { return null; } else { try { return this.objectMapper.readValue(bytes, 0, bytes.length, this.javaType); } catch (Exception ex) { throw new SerializationException(\u0026#34;Could not read MsgPack JSON: \u0026#34; + ex.getMessage(), ex); } } } public byte[] serialize(@Nullable Object value) throws SerializationException { if (value == null) { return new byte[0]; } else { try { return this.objectMapper.writeValueAsBytes(value); } catch (Exception ex) { throw new SerializationException(\u0026#34;Could not write MsgPack JSON: \u0026#34; + ex.getMessage(), ex); } } } static { DEFAULT_CHARSET = StandardCharsets.UTF_8; } } The only major noticeable change is an instance of MessagePackFactory being passed into the ObjectMapper. This would act as a bridge between binary and String formats of data between Redis and our Spring Boot application.\nTesting our changes (after clearing the previously utilized storage from redis gives us the following:\n127.0.0.1:6379\u0026gt; hgetall \u0026#34;Priscilla\u0026#34; 1) \u0026#34;Haymes\u0026#34; 2) \u0026#34;\\x83\\xa9firstName\\xa9Priscilla\\xa8lastName\\xa6Haymes\\xa8birthday\\xcf\\x00\\x00\\x01qn\\x19\\x8b \u0026#34; 127.0.0.1:6379\u0026gt; memory stats . . . 21) \u0026#34;keys.count\u0026#34; 22) (integer) 100 23) \u0026#34;keys.bytes-per-key\u0026#34; 24) (integer) 876 25) \u0026#34;dataset.bytes\u0026#34; 26) (integer) 15976 Compare the dataset.bytes from the current memory to the previously recorded one. 15976 bytes vs 32840 bytes, nearly 50% reduction already!\nBut wait, we can reduce it further. How, you ask. Compression! What if we compress the data and then store it? In our case it would work! This time, Snappy to the rescue!\nYour first question after this would be: compression and decompression takes time. Wouldn\u0026rsquo;t it be detrimental on production? Snappy has the answer to this too.\nIt does not aim for maximum compression, or compatibility with any other compression library; instead, it aims for very high speeds and reasonable compression.\nUsing Snappy is also as simple as adding the dependency in pom.xml, and a couple of lines of code changes. Just add Snappy.compress while serialization and Snappy.decompress while deserialization.\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.xerial.snappy\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;snappy-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.7.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Testing it again with the same inputs returns the following\n127.0.0.1:6379\u0026gt; hgetall \u0026#34;Priscilla\u0026#34; 1) \u0026#34;Haymes\u0026#34; 2) \u0026#34;7\\\\\\x83\\xa9firstName\\xa9Priscilla\\xa8la\\t\\x13`\\xa6Haymes\\xa8birthday\\xcf\\x00\\x00\\x01qn\\x19\\x8b \u0026#34; 127.0.0.1:6379\u0026gt; memory stats . . . 21) \u0026#34;keys.count\u0026#34; 22) (integer) 100 23) \u0026#34;keys.bytes-per-key\u0026#34; 24) (integer) 873 25) \u0026#34;dataset.bytes\u0026#34; 26) (integer) 15720 You can see that the size of the data set is smaller, 15720 bytes vs 15976 bytes, a marginal difference, but with larger amounts of data, this difference increases.\nIn my case, cleaning and restructuring the data, and utilizing the above techniques, we brought down the memory usage from 2GB to less than 500MB.\nThe full code can be found on my Github for redis-util.\nSpecial mention to Rahul Chopda (@_RahulChopda) for his guidance! You have been a best mentor anyone could ask for!\n","permalink":"https://darshit.dev/posts/reduce-redis-memory-usage/","summary":"\u003cp\u003eYes, you read that right.\u003c/p\u003e\n\u003cp\u003eTo give you some context, some time ago, our (my org\u0026rsquo;s) Redis usage was un-tracked \u0026ndash; meaning we didn\u0026rsquo;t know why our Redis memory was being occupied as much as it was. Our 2.5GB of Redis ElastiCache was almost close to being full, and if it somehow reached its limit, our system would start to fail. Though there were fallbacks in place, Redis could turn out to be a bottle-neck.\u003c/p\u003e","title":"How to achieve a 50% reduction in Redis memory usage"},{"content":"IntelliJ IDEA is an awesome IDE, and a lesser known and used feature is Live Templates.\nLive Templates enable you to use code snippets with just a few keystrokes. A lot of great ones are provided out-of-the-box by IntelliJ. You can view them using the shortcut press Double Shift and then typing Live Templates. The shortcut works regardless of the OS you\u0026rsquo;re currently using (and I am too lazy to specify OS specific menus).\nSome of the examples of Live Templates are:\nTyping psvm replaces it with\npublic static void main(String[] args){ } Typing psfs magically turns it into\npublic static final String I was recently refactoring a lot of classes and I had to replace a lot of legacy logging initialization statements to using slf4j logging library like the following:\nimport org.slf4j.Logger; import org.slf4j.LoggerFactory; public class LoggerTest { public static final Logger logger = LoggerFactory.getLogger(LoggerTest.class); } I had more than 30 different classes to refactor as the above, and I certainly didn\u0026rsquo;t want to painstakingly write everything by hand again (confirms that I\u0026rsquo;m lazy).\nFortunately, IntelliJ Live Templates came to my rescue! I fired up the Live Templates menu using the shortcut mentioned above, and clicked on the + button at the top right.\nI then clicked on Live Template button. The UI now points to the bottom which asks you to put an abbreviation.\nLet\u0026rsquo;s input the abbreviation as psfl which stands for public static final Logger, which can be also put in the description.\nWrite the following code in the Template text box:\npublic static final Logger logger = LoggerFactory.getLogger(); But hang on, the IDE gives us a warning to define a context where it would be used at. We want the template to be only used in Java, so we click on the Define button, and select Java.\nYou may now notice the IDE now applies syntax highlighting on the template.\nWait, we are still not there yet. I certainly don\u0026rsquo;t want to manually write every class name inside the getLogger function! At this point, I was not sure how I could achieve that. Cue in a bit of googling, stackoverflow again came to the rescue.\nI found the following answer: https://stackoverflow.com/a/8552882/4840501\npublic static final org.slf4j.Logger logger = org.slf4j.LoggerFactory.getLogger($CLASS_NAME$); $END$ So I copy-pasted the code in my template screen(what did you expect? :P)\nYou\u0026rsquo;d then need to define what $CLASS_NAME$ means. To do that, click on the Edit Variables button and select className() in the Expression box.\nThe $END$ variable means where you want your cursor at, after the template is applied.\nClick on Apply and Ok.\nWe\u0026rsquo;re done!\nFire up your classes and refactor with 10x speed!\nRelevant link: https://www.jetbrains.com/help/idea/creating-and-editing-live-templates.html\n","permalink":"https://darshit.dev/posts/using-intellij-idea-live-templates/","summary":"\u003cp\u003eIntelliJ IDEA is an awesome IDE, and a lesser known and used feature is Live Templates.\u003c/p\u003e\n\u003cp\u003eLive Templates enable you to use code snippets with just a few keystrokes. A lot of great ones are provided out-of-the-box by IntelliJ. You can view them using the shortcut press \u003ccode\u003eDouble Shift\u003c/code\u003e and then typing \u003ccode\u003eLive Templates\u003c/code\u003e. The shortcut works regardless of the OS you\u0026rsquo;re currently using (and I am too lazy to specify OS specific menus).\u003c/p\u003e","title":"Using IntelliJ IDEA Live Templates"}]