[{"content":"How do you define and use constants in Java?\nMost advice on Internet has the following opinions:\n Declare public static final for constants in a class Do not use Interfaces for constants  The most common way to define a constant is in a class and using public static final. One can then use the constant in another class using ClassName.CONSTANT_NAME. Constants are usually defined in upper cases as a rule, atleast in Java.\nSo if I were to define a constant for the value of Pi(π), it would be something like:\npublic final class Constants { public static final double PI = 3.14; } This can then be used as Constants.PI whenever we want to reference the value of Pi.\nAnother way one can define constants is by the use of interfaces.\npublic interface Constants { double PI = 3.14; } However, this is not recommended by most sources on the internet. Why? Because it is an anti-pattern.\nBut is it really an Anti-pattern? Let\u0026rsquo;s examine the difference by using both the methods.\n Creating a Constants class:  package constants; public final class MathConstantsClass { public static final double PI = 3.14; } Creating an interface:  package constants; public interface MathConstantsInterface { double PI = 3.14; } Let us define another interface which will help us test both the above methods.\npackage operations; public interface CircleArea { double calculate(double radius); } The above interface would help us define a contract to calculate the area of a circle. As we know, the area of a circle is dependent only on its radius, and thus is reflected in the above interface.\nThe following class provides the implementation of calculating the area of a circle.\nimport constants.MathConstantsClass; import operations.CircleArea; public class MathConstantsClassImplementation implements CircleArea { public double calculate(double radius) { return MathConstantsClass.PI * radius * radius; } } To test the the above code, let us write a Test class using JUnit.\nimport operations.CircleArea; import org.junit.jupiter.api.Test; import static org.junit.jupiter.api.Assertions.*; class MathConstantsClassImplementationTest { @Test void calculate() { CircleArea area = new MathConstantsClassImplementation(); double circleArea = area.calculate(1.0); assertEquals(3.14, circleArea); } } If you run the above piece of test code, the test would pass.\nFor testing how we can use the constants with Interface, let\u0026rsquo;s write another class called MathConstantsInterfaceImplementation.\nimport constants.MathConstantsInterface; import operations.CircleArea; public class MathConstantsInterfaceImplementation implements MathConstantsInterface, CircleArea { public double calculate(double radius) { return PI * radius * radius; } } Similarly a test for the above class is as follows:\nimport operations.CircleArea; import org.junit.jupiter.api.Test; import static org.junit.jupiter.api.Assertions.*; class MathConstantsInterfaceImplementationTest { @Test void calculate() { CircleArea area = new MathConstantsInterfaceImplementation(); double circleArea = area.calculate(1.0); assertEquals(3.14, circleArea); } } The above Test would pass. However, the argument against the implementation is that it is not a good practice as there could be field shadowing, and that will override the original value of the constant within the class.\nIt can be better understood with the following example:\nimport constants.MathConstantsInterface; import operations.CircleArea; public class MathConstantsWithInterfaceImplementationAndConstantShadowing implements MathConstantsInterface, CircleArea { private static final double PI = 200; public double calculate(double radius) { return PI * radius * radius; } } If, by chance, someone overrode the value of PI inside the class, it would lead to an incorrect output. It can be easily verified by the following test.\nimport operations.CircleArea; import org.junit.jupiter.api.Test; import static org.junit.jupiter.api.Assertions.*; class MathConstantsWithInterfaceImplementationAndConstantShadowingTest { @Test void calculate() { CircleArea area = new MathConstantsWithInterfaceImplementationAndConstantShadowing(); double circleArea = area.calculate(1.0); assertEquals(3.14, circleArea); } } The above test fails. The answer returned by calculate() is 200.0 instead of the expected 3.14. Another argument is, using the interface would pollute the namespace and also lead to the value propagated across the subclasses.\nThe above arguments are valid, and hold true.\nHowever, what no one mentions is that you can still directly use the constants from the interface without implementing the interface. Just like the first example where we use MathConstantsClass.PI, we can also use MathConstantsInterface.PI without affecting the namespace and inheritance and shadowing issues.\nThis can also be easily verified:\nimport constants.MathConstantsInterface; import operations.CircleArea; public class MathConstantsInterfaceWithoutImplementation implements CircleArea { public double calculate(double radius) { return MathConstantsInterface.PI * radius * radius; } } Test class:\nimport operations.CircleArea; import org.junit.jupiter.api.Test; import static org.junit.jupiter.api.Assertions.*; class MathConstantsInterfaceWithoutImplementationTest { @Test void calculate() { CircleArea area = new MathConstantsInterfaceWithoutImplementation(); double circleArea = area.calculate(1.0); assertEquals(3.14, circleArea); } } It would make no difference to our way of implementation. Even the number of imports remain same. Moreover, you do not need additional boilerplate of public static final as members in an interface are public static final by default.\npublic static final double PI = 3.14; vs\ndouble PI = 3.14; What would you prefer? Cleaner code, anyone?\nI have seen most constants almost grouped together if they are used throughout the application. You could also suggest that interface should only be used for contracts, and in most cases they are. However, keeping an interface for solely storing constants doesn\u0026rsquo;t seem to be wrong to me either!\nUnless, of course, some developer tries to implement a class which solely contains constants \u0026ndash; which would beget the question \u0026ndash; WHY?\nYou can check out the code at my Github: https://github.com/darshitpp/JavaConstants\nReferences:\n Constants in Java: Patterns and Anti-Patterns  ","permalink":"https://darshit.dev/posts/java-constants-interface/","summary":"How do you define and use constants in Java?\nMost advice on Internet has the following opinions:\n Declare public static final for constants in a class Do not use Interfaces for constants  The most common way to define a constant is in a class and using public static final.","title":"The Java Constants Interface Anti-Pattern"},{"content":"I wrote this earlier on a Github gist, but putting it here for a consolidated reference.\nWant to change Java Version/JAVA_HOME for Ant builds?  Open ~/.antrc file by running vim ~/.antrc Add JAVACMD=\u0026lt;NEW_JAVA_HOME\u0026gt;/bin/java and save   The Ant wrapper script for Unix will source (read and evaluate) the file ~/.antrc before it does anything. On Windows, the Ant wrapper batch-file invokes %HOME%\\antrc_pre.bat at the start and %HOME%\\antrc_post.bat at the end. You can use these files, for example, to set/unset environment variables that should only be visible during the execution of Ant.\n  The wrapper scripts use the following environment variables (if set):\n JAVACMD—full path of the Java executable. Use this to invoke a different JVM than JAVA_HOME/bin/java(.exe). ANT_OPTS—command-line arguments that should be passed to the JVM. For example, you can define system properties or set the maximum Java heap size here. ANT_ARGS—Ant command-line arguments. For example, set ANT_ARGS to point to a different logger, include a listener, and to include the -find flag. Note: If you include -find in ANT_ARGS, you should include the name of the build file to find, even if the file is called build.xml.   Source: https://ant.apache.org/manual/running.html\n","permalink":"https://darshit.dev/posts/change-java-version-ant/","summary":"I wrote this earlier on a Github gist, but putting it here for a consolidated reference.\nWant to change Java Version/JAVA_HOME for Ant builds?  Open ~/.antrc file by running vim ~/.","title":"How to change Java Version/JAVA_HOME for Ant?"},{"content":"A couple of weeks ago, I was tasked with figuring out a way to enable two way SSL. I am a programmer, and have had only a limited experience with networking concepts like SSL/TLS in my short career. So I turned up blank on how I could make it possible. Moreover, the terminology you\u0026rsquo;d find online is not uniform. From a programming point of view, the term \u0026ldquo;Two way SSL\u0026rdquo; led me to limited results, and I soon realized that other communities have different terminology. For example the \u0026ldquo;Two way SSL\u0026rdquo; is also known as \u0026ldquo;Mutual TLS\u0026rdquo; or \u0026ldquo;mTLS\u0026rdquo; or \u0026ldquo;Client Certificate Authentication\u0026rdquo; in Cloud/DevOps communitites. This makes finding the right resources online more difficult.\nOur services have SSL enabled, but only the usual one \u0026ndash; similar to the one you\u0026rsquo;d find while visiting this website, but this was a unique thing for me as I didn\u0026rsquo;t even know two way SSL existed. I figured out how it works. However, there were more problems with trying to understand how to implement this. Most guides that I found on the internet were very incomplete, and straight away skipped many parts for someone who\u0026rsquo;d be new to this. This is my attempt at explaining what I have learned, and documenting the same for future reference. It will not explain how two way SSL works, but how to make it work. If you need a quick refresher however, I would direct you to this easy to understand article by Cloudflare explaining where and how mTLS is used.\nThis guide is only for Unix like systems like macOS or Linux. Though I tried this on Windows, but could not make it work.\nPrerequisites  Nginx sudo privileges on your system  Installing and Configuring Nginx Install Install1 nginx using apt command on your Linux system.\nsudo apt update sudo apt install nginx This will install all of Nginx on the path /opt/nginx. All the configuration files we will be editing for two-way SSL would be found within this directory.\nConfigure Nginx to start Before starting up Nginx for use, we need to enable some ports on the firewall that our Nginx can listen incoming connections from.\nsudo ufw app list Output:\nAvailable applications: Nginx Full Nginx HTTP Nginx HTTPS OpenSSH The utility ufw can be used to manage our firewall. Though a knowledge of ufw is not necessary for us, more information can be found here.\nYou can see in the above output that the utility responds us with four profiles. When we installed Nginx, it registered itself with the ufw utility with three profiles.\n Nginx HTTP allows Nginx to listen through port 80, for normal HTTP traffic. Nginx HTTPS allows Nginx to listen through port 443, for HTTPS traffic. Nginx Full is a combination of the above both, enabling port 80 and 443 both.  We will enable Nginx Full as we have to use our server for SSL, but using normal HTTP connections is not an uncommon use-case either. To enable it, run:\nsudo ufw allow \u0026#39;Nginx Full\u0026#39; You should see the activated profile if you run the below command\nsudo ufw status Output:\nStatus: active To Action From -- ------ ---- OpenSSH ALLOW Anywhere Nginx Full ALLOW Anywhere OpenSSH (v6) ALLOW Anywhere (v6) Nginx Full (v6) ALLOW Anywhere (v6) The Nginx service should already be up and running now. You can check by executing\nsystemctl status nginx Output:\n● nginx.service - A high performance web server and a reverse proxy server Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) Active: active (running) since Fri 2018-04-20 16:08:19 UTC; 3 days ago Docs: man:nginx(8) Main PID: 2369 (nginx) Tasks: 2 (limit: 1153) CGroup: /system.slice/nginx.service ├─2369 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; └─2380 nginx: worker process Creating Certificates Terminology  Certificate Authority (CA): This is an Organization which provides you a Certificate (the .crt file). In reality, anyone (including yourself) can be the CA which issues certificates Certificate Signing Request (CSR .csr): An \u0026ldquo;input form\u0026rdquo; with details (like Name, Organization, Address, etc.) filled by the requester of the certificate which is submitted to the CA Private Key (.key): The private key file used by the CA in conjunction with CSR to sign and generate the certificates Certificate (.crt): The certificate generated by the CA Self Signed Certificate: Consider yourself as a Certificate Authority (CA) and generate the .crt files.  Now that we know the terminology, it would be easier to proceed with generating the certificates. The following part of the tutorial requires root/superuser privileges, so switch to the super user using the sudo su command.\nCreate a directory called certs under the root of the file-system which will hold all the certificates and related files.\n# Create directory mkdir /certs # Change directory to /certs cd /certs # Verify the present working directory pwd Output:\n/certs In this tutorial, we would be designating ourselves as a Certificate Authority, and then self-sign and generate the certificates.\nGenerate Certificate Authority (CA) files We would be first generating a CA key, which would be the basis for all further certificate generation.\nopenssl genrsa -des3 -out ca.key 4096 Output:\nGenerating RSA private key, 4096 bit long modulus (2 primes) .............................................................++++ ....................................................................................................................................................................................++++ e is 65537 (0x010001) Enter pass phrase for ca.key:\u0026lt;passphrase\u0026gt; Verifying - Enter pass phrase for ca.key:\u0026lt;passphrase\u0026gt; Command options:\n genrsa: generate RSA private key -des3: encrypts the output key using des3 encryption -out: specifying the output key file 4096: size of private key in bits  This generates a file named ca.key in the current directory. You would have to provide a password/passphrase for the key. For the purposes of this tutorial, I\u0026rsquo;ll be using the same passphrase whenever required.\n\u0026lt;passphrase\u0026gt; = root\nThe next step is the generation of ca.crt\nopenssl req -new -x509 -days 3650 -key ca.key -out ca.crt Output:\nEnter pass phrase for ca.key:\u0026lt;passphrase\u0026gt; Command options:\n req: used for creating certificate requests -new: generates new certificate request -x509: outputs a new self-signed certificate instead of a certificate request -days 3650: validity of certificate (in this case, 10 years/3650 days) -key: RSA key to be used for generating the certificate -out: output file for the certificate  Once you enter the passphrase (which is the same as we put in the previous step), it\u0026rsquo;ll ask you to provide more information for the self-signed certificate.\nYou are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [AU]: State or Province Name (full name) [Some-State]: Locality Name (eg, city) []: Organization Name (eg, company) [Internet Widgits Pty Ltd]:CertAuth Organizational Unit Name (eg, section) []: Common Name (e.g. server FQDN or YOUR name) []: Email Address []: Note the Organization Name parameter is named as CertAuth for this example. This is because we are a CA and CAs should ideally be independent to enable other parties to trust other parties and establish a chain of trust.\nA PEM file certificate would also be needed. This file is way of encoding the certificates.2 To create a PEM file, simply do the following:\ncat ca.key \u0026gt; ca.pem cat ca.key \u0026gt;\u0026gt; ca.pem The ca.key would be something like\n-----BEGIN RSA PRIVATE KEY----- Proc-Type: 4,ENCRYPTED DEK-Info: DES-EDE3-CBC,0E2D38C130456B75 3+0Em2EKRkmCCu79bR7E2uFy/G1huIGEGsItwDf0C70Hf2bmUUDYazK/CPZxZCut PDximngoGaLSdLQ2HWGjjCe59pJxxZknxHu9QVy3mIWLixAZWevDUnoK1q+Wqy0M -----END RSA PRIVATE KEY----- -----BEGIN CERTIFICATE----- MIIFSzCCAzOgAwIBAgIUeawaQJUIAPKOKhrIJDjMVCYVx4MwDQYJKoZIhvcNAQEL BQAwNTELMAkGA1UEBhMCQVUxEzARBgNVBAgMClNvbWUtU3RhdGUxETAPBgNVBAoM -----END CERTIFICATE----- Generating Client/User Certificates At this point, we have three files in the certs directory.\nca.key ca.crt ca.pem We now would be generating client/user certificates. The command to generate the user.key is similar to the one used to create the ca.key\nopenssl genrsa -des3 -out user.key 4096 Output:\nGenerating RSA private key, 4096 bit long modulus (2 primes) .....................................................................................................................................................++++ .......................++++ e is 65537 (0x010001) Enter pass phrase for user.key: Verifying - Enter pass phrase for user.key: As mentioned earlier, the passphrase to be used for user.key is still the same.\nThe client/user certificate aren\u0026rsquo;t supposed to be self-signed, and we would need to generate a CSR. It means the signing is to be done by a CA(even though in this case, we own the CA!). The way to do this is\nopenssl req -new -key user.key -out user.csr Output:\nEnter pass phrase for user.key:\u0026lt;passphrase\u0026gt; You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [AU]: State or Province Name (full name) [Some-State]: Locality Name (eg, city) []: Organization Name (eg, company) [Internet Widgits Pty Ltd]:User Organizational Unit Name (eg, section) []: Common Name (e.g. server FQDN or YOUR name) []: Email Address []: Please enter the following \u0026#39;extra\u0026#39; attributes to be sent with your certificate request A challenge password []: An optional company name []: The Organization Name would be User as this certificate is for a Client/User. DO NOT keep it the same as the one for CA.\nThe next step would be to create a User Certificate from the User CSR.\nopenssl x509 -req -days 365 -in user.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out user.crt Output:\nSignature ok subject=C = AU, ST = Some-State, O = User Getting CA Private Key Enter pass phrase for ca.key:\u0026lt;passphrase\u0026gt; Command options:\n x509: standard format for public key certificates -CA: the CA certificate -CAkey: the key to generate the certificate from -set_serial 01: the serial version of the certificate to be generated. The user certificate can be regenerated by incrementing the serial number from the same user.csr after 365 days when it expires.  You can see that it displays data from the CSR, and then uses the CA key to generate user.crt.\nTo enable us to use the certificate from a web browser, we would need to create the certificate in the PFX file format.\nopenssl pkcs12 -export -out user.pfx -inkey user.key -in user.crt -certfile ca.crt Output:\nEnter pass phrase for user.key:\u0026lt;passphrase\u0026gt; Enter Export Password:\u0026lt;passphrase\u0026gt; Verifying - Enter Export Password:\u0026lt;passphrase\u0026gt; You can verify if the generated certificate can be decrypted using the CA certificate by the following command\nopenssl verify -verbose -CAfile ca.crt user.crt Output:\nuser.crt: OK The files that we currently have in the directory are\nca.key ca.crt ca.pem user.key user.csr user.crt user.pfx Generating Server Certificates This is similar to generating the User certificates, with the following commands\nGenerate the Server key. For server certificates, the standard naming convention seems to be \u0026lt;website-domain-name\u0026gt;.\u0026lt;key\u0026gt;\nopenssl genrsa -out nginx.mssl.com.key 4096 Output:\nGenerating RSA private key, 4096 bit long modulus (2 primes) .....................................++++ .........................++++ e is 65537 (0x010001) Use the above generated key to generate a CSR.\nopenssl req -new -key nginx.mssl.com.key -out nginx.mssl.com.csr Output:\nYou are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [AU]: State or Province Name (full name) [Some-State]: Locality Name (eg, city) []: Organization Name (eg, company) [Internet Widgits Pty Ltd]:Server Organizational Unit Name (eg, section) []: Common Name (e.g. server FQDN or YOUR name) []:nginx.mssl.com Email Address []: Please enter the following \u0026#39;extra\u0026#39; attributes to be sent with your certificate request A challenge password []: An optional company name []: Make sure to put the Organization Name as Server and Common Name (which is the website name) as nginx.mssl.com\nWe can now use the CSR along with the CA files to generate the CRT for our server.\nopenssl x509 -req -days 365 -sha256 -in nginx.mssl.com.csr -CA ca.crt -CAkey ca.key -set_serial 1 -out nginx.mssl.com.crt Output:\nSignature ok subject=C = AU, ST = Some-State, O = Server, CN = nginx.mssl.com Getting CA Private Key Enter pass phrase for ca.key:\u0026lt;passphrase\u0026gt; All the certificates are now ready for our use!\nca.key ca.crt ca.pem user.key user.csr user.crt user.pfx nginx.mssl.com.key nginx.mssl.com.csr nginx.mssl.com.crt Setting up our \u0026ldquo;Website\u0026rdquo; with Nginx Of course, we aren\u0026rsquo;t setting up a real website. But we do want to make our SSL authentication work on the domain nginx.mssl.com. We can do this by a little \u0026ldquo;hack\u0026rdquo; by changing our /etc/hosts file.\nFire up a new shell, and use\nsudo vim /etc/hosts Add the following line to the file and save.\n127.0.0.1 nginx.mssl.com This will enable your local machine to resolve the domain nginx.mssl.com to your locahost.\nThe website will not work at the moment \u0026ndash; you\u0026rsquo;d have to specify the sources/web pages it needs to serve when requested.\nCreate a file index.html on the directory path /usr/share/nginx/mssl with the contents:\n\u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!-mutual ssl test\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; If the TLS handshake is successful, the web server should serve the file created above.\nConfiguring the Nginx server to enable two way SSL All our certificates are at root in /certs directory. For simplicity, we would be copying the certificates to /etc/nginx/certs directory.\ncp -r /certs /etc/nginx/certs Also ensure that the certificates can be used by nginx service by providing them the access\nchmod 777 -R certs/ We would not be fiddling with the default nginx configuration which is present in the nginx.conf file. Instead, we would be creating a new file called proxy.conf using in the /etc/nginx/sites-available directory.\nCreate the file proxy.conf using the command\ncd /etc/nginx/sites-available touch proxy.conf Enter the contents as the following (Notice the comments have more explanation):\nserver { # Listen on port 443 for HTTPS connections listen 443; # Turn SSL on ssl on; # Name of the server/website server_name nginx.mssl.com; # See https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_ssl_server_name proxy_ssl_server_name on; # This is the server SSL certificate ssl_certificate /etc/nginx/certs/nginx.mssl.com.crt; # This is the server certificate key ssl_certificate_key /etc/nginx/certs/nginx.mssl.com.key; # Important: # This is the CA cert against which the client/user will be validated # In our case since the Server and the Client certificate is # generated from the same CA, we use the ca.crt # But in actual production, the Client certificate might be # created from a different CA ssl_client_certificate /etc/nginx/certs/ca.crt; # Enables mutual TLS/two way SSL to verify the client ssl_verify_client on; # Number of intermediate certificates to verify. Good explanation of # certificate chaining can be found at # https://cheapsslsecurity.com/p/what-is-ssl-certificate-chain/ ssl_verify_depth 2; # Any error during the connection can be found on the following path error_log /var/log/nginx/error.log debug; ssl_prefer_server_ciphers on; ssl_protocols TLSv1.1 TLSv1.2; ssl_ciphers \u0026#39;ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:ECDHE-RSA-RC4-SHA:ECDHE-ECDSA-RC4-SHA:RC4-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!3DES:!MD5:!PSK\u0026#39;; keepalive_timeout 10; ssl_session_timeout 5m; # Matches the \u0026#34;root\u0026#34; of the website # If TLS handshake is successful, the request is routed to this block location / { # path from which the website is served from root /usr/share/nginx/mssl; # index file name index index.html index.htm; } } Nginx has a good Beginner\u0026rsquo;s Guide to Nginx.\nTo enable Nginx to use the above configuration, we also have to link the same in the /etc/nginx/sites-enabled directory.\nTo accomplish this, use\nln -s /etc/nginx/sites-available/proxy.conf /etc/nginx/sites-enabled/proxy.conf This creates a symbolic link into /etc/nginx/sites-enabled/proxy.conf from /etc/nginx/sites-available/proxy.conf. Consider it as you having many server configurations in the sites-available, but only what you chose to \u0026ldquo;enable\u0026rdquo; in the sites-enabled will be active.\nWe now just have to restart the Nginx for the configuration to be active!\nsystemctl restart nginx I\u0026rsquo;ll be using Postman to test our changes. However, you\u0026rsquo;ll need to configure Postman to send the Client Certificates with the request3.\nTo configure the Certificates, navigate to Settings -\u0026gt; Certificates Tab.\nThere will be a section to add the CA Certificate named CA Certificates, and this certificate should be a PEM file. Select the ca.pem from /etc/nginx/certs. A mistake would be to select the file from the root directory /certs but this will not work as Postman wouldn\u0026rsquo;t be able to access the file.\nThere would be another section below for Client Certificates. Click on Add Certificate, and put the details as the following:\n Host: nginx.mssl.com CRT File: /etc/nginx/certs/user.crt KEY File: /etc/nginx/certs/user.key PFX File: /etc/nginx/certs/user.pfx Passphrase: \u0026lt;passphrase\u0026gt;  Now try to fire a GET request to the domain https://nginx.mssl.com. If everything was configured successfully, you\u0026rsquo;ll get the following response:\n\u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!-mutual ssl test\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; If there\u0026rsquo;s an error in the configuration, you\u0026rsquo;ll get the following error response:\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;400 No required SSL certificate was sent\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body bgcolor=\u0026#34;white\u0026#34;\u0026gt; \u0026lt;center\u0026gt; \u0026lt;h1\u0026gt;400 Bad Request\u0026lt;/h1\u0026gt; \u0026lt;/center\u0026gt; \u0026lt;center\u0026gt;No required SSL certificate was sent\u0026lt;/center\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;center\u0026gt;nginx/1.14.0 (Ubuntu)\u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Hope this post was of some help!!\nReference:\n This article is good for the demo part. The post Client Certificate Auth With Nginx was instrumental in explaining the ssl_client_certificate directive and how to use it. This post is as close to perfection as it gets regarding the steps for generating Certificates, but I couldn\u0026rsquo;t manage to make it work fully with Nginx. (Especially because it skips the demo part + it could be a little more descriptive with generation of the certificates) This article is good, but still unclear for someone starting out. I used this article to actually learn about generating the certificates especially because it provides easy commands and decent explanation.    The main resource for installing Nginx is this tutorial by DigitalOcean. All the relevant steps have been described in my article. \u0026#x21a9;\u0026#xfe0e;\n More info here \u0026#x21a9;\u0026#xfe0e;\n Client Certificates: Postman Learning Center \u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://darshit.dev/posts/two-way-ssl-nginx/","summary":"A couple of weeks ago, I was tasked with figuring out a way to enable two way SSL. I am a programmer, and have had only a limited experience with networking concepts like SSL/TLS in my short career.","title":"How To Implement Two Way SSL With Nginx"},{"content":"I currently work as a Software Engineer with Gupshup.\nI am involved in the computing community by volunteering at ACM. I have been an editor with ACM XRDS, and I\u0026rsquo;m now a member of the ACM Future of Computing Academy (FCA). You can find the work that FCA is doing at https://acm-fca.org/\nMy professional work and interests include working with Java, Spring Boot and related ecosystems, and learning about designing Scalable Software Architectures and Systems.\nMy favourite IDE is IntelliJ IDEA!\nYou can reach out to me on Twitter @darshitpp and LinkedIn, and you can find my Resume/CV here.\n","permalink":"https://darshit.dev/about/","summary":"I currently work as a Software Engineer with Gupshup.\nI am involved in the computing community by volunteering at ACM. I have been an editor with ACM XRDS, and I\u0026rsquo;m now a member of the ACM Future of Computing Academy (FCA).","title":"About"},{"content":"Yes, you read that right.\nTo give you some context, some time ago, our (my org\u0026rsquo;s) Redis usage was un-tracked \u0026ndash; meaning we didn\u0026rsquo;t know why our Redis memory was being occupied as much as it was. Our 2.5GB of Redis ElastiCache was almost close to being full, and if it somehow reached its limit, our system would start to fail. Though there were fallbacks in place, Redis could turn out to be a bottle-neck.\nIn this post, I would try to explain how we reduced the storage occupied by the data by more than 50%. This would also kind of be a step by step guide from the basics, so if you\u0026rsquo;re just interested in how Redis is being used, just skip the and go to the Optimization section.\nBasic Setup I would be using the latest version of Spring Boot from https://start.spring.io. Firstly, select our two of our main dependencies - Spring Boot Web and Spring Data Reactive Redis.\nYou would find these in the pom.xml file when you download the starter project.\nThe Spring Boot Web is for building basic web applications with Spring Boot, whereas Spring Data Reactive Redis would be used for connecting and using Redis inside the application. At its core, the Redis dependency by default uses the Lettuce Redis client, and is supported by the latest versions of Spring Boot.\nNote that I\u0026rsquo;m going to skip the installation of Redis, as there are other guides available for every operating system. You do need the Redis Server to be started for our application to work successfully.\nAfter downloading the basic application, you\u0026rsquo;ll need to extract and open it in your favourite IDE (my favourite one is IntelliJ IDEA).\nIn my case the project name is redis-util, and you\u0026rsquo;ll find my \u0026ldquo;base packages\u0026rdquo; to be named com.darshitpp.redis.redisutil. This base package would have a class called RedisUtilApplication, which in my case has the following configuration.\n@SpringBootApplication @ComponentScan(basePackages = {\u0026#34;com.darshitpp.redis.redisutil\u0026#34;}) public class RedisUtilApplication { public static void main(String[] args) { SpringApplication.run(RedisUtilApplication.class, args); } } I have manually added the @ComponentScan annotation to specify a top-level package name under where Spring should look for defined Beans/Configurations.\nTo connect to Redis, I create a configuration class called LettuceRedisConfiguration, under a new package named configuration(note that this should be under the basePackages path defined above.\nYou could define the configuration in the RedisUtilApplication class itself, but I want this to be as \u0026ldquo;production-ready\u0026rdquo; as possible. Thus, it\u0026rsquo;s a good practice to separate out your different parts of application.\nMy configuration class is\n@Configuration public class LettuceRedisConfiguration { @Bean public LettuceConnectionFactory redisConnectionFactory() { return new LettuceConnectionFactory(new RedisStandaloneConfiguration(\u0026#34;localhost\u0026#34;, 6379)); } } It is a very simple class, which has the configuration of which URL to connect to for Redis. In my case, it is localhost, but in most production apps, it would be an external Redis server. Port 6379 is the default port on which the Redis server starts. This Bean would return us a \u0026ldquo;factory\u0026rdquo; of Redis connections. Think of this as something which would allow you to connect to Redis when required.\nAt this point, my package structure looks like:\n-\u0026gt;src -\u0026gt;main -\u0026gt;java -\u0026gt;com.darshitpp.redis.redisutil -\u0026gt;configuration Now that we know how to connect to a Redis server, we need to figure out what data we need to store in Redis. In our case, we would be storing User data. This is the \u0026ldquo;domain model\u0026rdquo; of our application (domain model could be translated to a table in a Database, but we don\u0026rsquo;t have a table in our scenario). This User is stored in a package called domain.\nThe User would have three fields, namely, firstName, lastName, and birthday.\nBefore storing the objects in Redis, it is a good idea to identify how you will store the data so that it\u0026rsquo;s efficient to fetch it back. What that means is Redis being a simple Key-Value store, you would need to identify the Key you would be storing the Value with. In our case, I am choosing firstName as the key. The data would be stored in a hash, so the hashKey that we select would be the lastName and the value mapped to the hashKey is the User object.\nThis is because Hashes in Redis have the following structure:\nkey1 --- hashKey1 === value1 --- hashKey2 === value2 --- hashKey3 === value3 key2 --- hashKey4 === value4 --- hashKey5 === value5 . . . You could also imagine it as a tree with the top level nodes being the Keys, the immediate next level to be hashKeys, and the leaf nodes to be the values. To access value2, you would need to have key1 and hashKey2.\nOur example is a bit incorrect, as a User could have same key=firstName and hashKey=lastName as another user, and Redis will overwrite value. However, for brevity, we will assume there are unique Users using our application.\nWe would now be creating a controller class called NormalController which would act as an entry point for our API. We have named it NormalController for reasons that will be clear further in this article.\n@RestController @RequestMapping(\u0026#34;/normal\u0026#34;) public class NormalController { private final NormalService normalService; @Autowired public NormalController(NormalService normalService) { this.normalService = normalService; } @GetMapping(\u0026#34;/get\u0026#34;) public User get(@RequestParam(\u0026#34;firstName\u0026#34;) String firstName, @RequestParam(\u0026#34;lastName\u0026#34;) String lastName) { return normalService.get(firstName, lastName); } @PostMapping(\u0026#34;/insert\u0026#34;) public void insert(@RequestBody User user) { normalService.put(user); } @PostMapping(\u0026#34;/delete\u0026#34;) public void delete(@RequestParam(\u0026#34;firstName\u0026#34;) String firstName) { normalService.delete(firstName); } } NormalController also has a service named NormalService which is Autowired. The class should be defined in a new packaged named controller after which the package structure would look like\n-\u0026gt;src -\u0026gt;main -\u0026gt;java -\u0026gt;com.darshitpp.redis.redisutil -\u0026gt;configuration -\u0026gt;domain -\u0026gt;controller Our basic operations would be simple CRUD like operations which NormalService implements using a custom Operations interface.\npublic interface Operations { User get(String firstName, String lastName); void put(User user); void delete(String firstName); } To use Lettuce in our application, we need to do a couple of more things though. Just like to access JDBC, there\u0026rsquo;s a provision for a JdbcTemplate, you must similarly use a RedisTemplate to operate on Redis. We must also define in what format will Redis store the data inside it. By default, it stores data as a String. However, know that you\u0026rsquo;ll be storing User in Redis, and in order to facilitate the storage and fetch from Redis, you would need a way through which Redis will be able to identify and convert it back to the appropriate type of data you want.\nThink of this as talking with someone who doesn\u0026rsquo;t know the same language as you do. If you want to communicate with someone who only speaks Spanish, you would need to find a translator who would convert English into Spanish for you. This process of conversion and recovery is known as Serialization and Deserialization.\nEnglish to Spanish = Serialization Spanish to English = Deserialization\nThus, we need a translator or a Serializer in our case too. We would be using Jackson for this process. Jackson is a nifty library which Spring Boot supports out-of-the-box to handle Json.\nWe would need to create a Serializer which implements RedisSerializer for our purposes. In our case, I have created a class JsonRedisSerializer inside a new package called serializer.\nclass JsonRedisSerializer\u0026lt;T\u0026gt; implements RedisSerializer\u0026lt;T\u0026gt; { public static final Charset DEFAULT_CHARSET; private final JavaType javaType; private ObjectMapper objectMapper = new ObjectMapper() .registerModules(new Jdk8Module(), new JavaTimeModule(), new ParameterNamesModule(JsonCreator.Mode.PROPERTIES)) .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, true) .configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false) .configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false) .setSerializationInclusion(JsonInclude.Include.NON_NULL); public JsonRedisSerializer(Class\u0026lt;T\u0026gt; type) { this.javaType = JavaTypeHandler.getJavaType(type); } public T deserialize(@Nullable byte[] bytes) throws SerializationException { if (bytes == null || bytes.length == 0) { return null; } else { try { return this.objectMapper.readValue(bytes, 0, bytes.length, this.javaType); } catch (Exception ex) { throw new SerializationException(\u0026#34;Could not read JSON: \u0026#34; + ex.getMessage(), ex); } } } public byte[] serialize(@Nullable Object value) throws SerializationException { if (value == null) { return new byte[0]; } else { try { return this.objectMapper.writeValueAsBytes(value); } catch (Exception ex) { throw new SerializationException(\u0026#34;Could not write JSON: \u0026#34; + ex.getMessage(), ex); } } } static { DEFAULT_CHARSET = StandardCharsets.UTF_8; } } As you can see, it has two methods called serialize and deserialize. Each of these methods use the Jackson\u0026rsquo;s ObjectMapper for conversion.\nThere is also a class named JavaTypeHandler which helps you get the Type of the object you\u0026rsquo;re trying to serialize.\nfinal class JavaTypeHandler { static \u0026lt;T\u0026gt; JavaType getJavaType(Class\u0026lt;T\u0026gt; clazz) { return TypeFactory.defaultInstance().constructType(clazz); } } Consequently, we would also need a class which returns us a RedisTemplate which utilizes this serializer. I would name this class RedisSerializationBuilder.\npublic final class RedisSerializationBuilder { public static \u0026lt;T\u0026gt; RedisTemplate\u0026lt;String, T\u0026gt; getNormalRedisTemplate(final LettuceConnectionFactory factory, final Class\u0026lt;T\u0026gt; clazz) { JsonRedisSerializer\u0026lt;T\u0026gt; jsonRedisSerializer = new JsonRedisSerializer\u0026lt;\u0026gt;(clazz); RedisTemplate\u0026lt;String, T\u0026gt; redisTemplate = new RedisTemplate\u0026lt;\u0026gt;(); redisTemplate.setConnectionFactory(factory); redisTemplate.setDefaultSerializer(RedisSerializer.json()); redisTemplate.setKeySerializer(RedisSerializer.string()); redisTemplate.setValueSerializer(RedisSerializer.string()); redisTemplate.setHashKeySerializer(RedisSerializer.string()); redisTemplate.setHashValueSerializer(jsonRedisSerializer); redisTemplate.afterPropertiesSet(); return redisTemplate; } } Notice that the above method will return you a template specific to a particular domain model(in our case, the User) using Generics. It also specifies what connection factory is to be used, what should be the default key/value/hashKey/hashValue serializers.\nConsequently, the NormalService looks like\n@Service public class NormalService implements Operations{ private final RedisTemplate\u0026lt;String, User\u0026gt; redisTemplate; private final HashOperations\u0026lt;String, String, User\u0026gt; hashOperations; public NormalService(LettuceConnectionFactory redisConnectionFactory) { this.redisTemplate = RedisSerializationBuilder.getNormalRedisTemplate(redisConnectionFactory, User.class); this.hashOperations = this.redisTemplate.opsForHash(); } @Override public User get(String firstName, String lastName) { return hashOperations.get(firstName, lastName); } @Override public void put(User user) { hashOperations.put(user.getFirstName(), user.getLastName(), user); } @Override public void delete(String firstName) { hashOperations.delete(firstName); } } I then inserted a User, using the POST method, and URL: localhost:8080/normalService/insert Request Body:\n{ \u0026#34;firstName\u0026#34;: \u0026#34;Priscilla\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Haymes\u0026#34;, \u0026#34;birthday\u0026#34;: \u0026#34;2020-04-12T11:15:00Z\u0026#34; } If I then run this application for 100 Users, I find the following stats for the memory usage in Redis (I used the memory stats command using the redis-cli)\n21) \u0026#34;keys.count\u0026#34; 22) (integer) 100 23) \u0026#34;keys.bytes-per-key\u0026#34; 24) (integer) 1044 25) \u0026#34;dataset.bytes\u0026#34; 26) (integer) 32840 Using the hgetall command for a key gives me\n127.0.0.1:6379\u0026gt;hgetall \u0026#34;Priscilla\u0026#34; 1) \u0026#34;Haymes\u0026#34; 2) \u0026#34;{\\\u0026#34;firstName\\\u0026#34;:\\\u0026#34;Priscilla\\\u0026#34;,\\\u0026#34;lastName\\\u0026#34;:\\\u0026#34;Haymes\\\u0026#34;,\\\u0026#34;birthday\\\u0026#34;:1586690100000}\u0026#34; Notice that 2) gives us the actual type of data stored in Redis -\u0026gt; Json!\nOur basic structure for further optimizations is in place! Yay!\nOptimization MessagePack is here to the rescue! As I said, you\u0026rsquo;d need a \u0026ldquo;transalation\u0026rdquo; mechanism. What if the translator is an expert, and converts your English into Spanish in as few words as possible? MessagePack is the same!\nYou would need to add two more dependencies in your pom.xml file.\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.msgpack\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;msgpack-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.8.20\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.msgpack\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jackson-dataformat-msgpack\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.8.20\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; We create a controller called MsgPackController and a service called MsgPackService almost similar to NormalController and NormalService. We would create a MsgPackSerializer to serialize using MessagePack.\nclass MsgPackRedisSerializer\u0026lt;T\u0026gt; implements RedisSerializer\u0026lt;T\u0026gt; { public static final Charset DEFAULT_CHARSET; private final JavaType javaType; private ObjectMapper objectMapper = new ObjectMapper(new MessagePackFactory()) .registerModules(new Jdk8Module(), new JavaTimeModule()) .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, true) .configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false) .configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false) .setSerializationInclusion(JsonInclude.Include.NON_NULL); public MsgPackRedisSerializer(Class\u0026lt;T\u0026gt; type) { this.javaType = JavaTypeHandler.getJavaType(type); } public T deserialize(@Nullable byte[] bytes) throws SerializationException { if (bytes == null || bytes.length == 0) { return null; } else { try { return this.objectMapper.readValue(bytes, 0, bytes.length, this.javaType); } catch (Exception ex) { throw new SerializationException(\u0026#34;Could not read MsgPack JSON: \u0026#34; + ex.getMessage(), ex); } } } public byte[] serialize(@Nullable Object value) throws SerializationException { if (value == null) { return new byte[0]; } else { try { return this.objectMapper.writeValueAsBytes(value); } catch (Exception ex) { throw new SerializationException(\u0026#34;Could not write MsgPack JSON: \u0026#34; + ex.getMessage(), ex); } } } static { DEFAULT_CHARSET = StandardCharsets.UTF_8; } } The only major noticeable change is an instance of MessagePackFactory being passed into the ObjectMapper. This would act as a bridge between binary and String formats of data between Redis and our Spring Boot application.\nTesting our changes (after clearing the previously utilized storage from redis gives us the following:\n127.0.0.1:6379\u0026gt; hgetall \u0026#34;Priscilla\u0026#34; 1) \u0026#34;Haymes\u0026#34; 2) \u0026#34;\\x83\\xa9firstName\\xa9Priscilla\\xa8lastName\\xa6Haymes\\xa8birthday\\xcf\\x00\\x00\\x01qn\\x19\\x8b \u0026#34; 127.0.0.1:6379\u0026gt; memory stats . . . 21) \u0026#34;keys.count\u0026#34; 22) (integer) 100 23) \u0026#34;keys.bytes-per-key\u0026#34; 24) (integer) 876 25) \u0026#34;dataset.bytes\u0026#34; 26) (integer) 15976 Compare the dataset.bytes from the current memory to the previously recorded one. 15976 bytes vs 32840 bytes, nearly 50% reduction already!\nBut wait, we can reduce it further. How, you ask. Compression! What if we compress the data and then store it? In our case it would work! This time, Snappy to the rescue!\nYour first question after this would be: compression and decompression takes time. Wouldn\u0026rsquo;t it be detrimental on production? Snappy has the answer to this too.\n It does not aim for maximum compression, or compatibility with any other compression library; instead, it aims for very high speeds and reasonable compression.\n Using Snappy is also as simple as adding the dependency in pom.xml, and a couple of lines of code changes. Just add Snappy.compress while serialization and Snappy.decompress while deserialization.\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.xerial.snappy\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;snappy-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.7.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Testing it again with the same inputs returns the following\n127.0.0.1:6379\u0026gt; hgetall \u0026#34;Priscilla\u0026#34; 1) \u0026#34;Haymes\u0026#34; 2) \u0026#34;7\\\\\\x83\\xa9firstName\\xa9Priscilla\\xa8la\\t\\x13`\\xa6Haymes\\xa8birthday\\xcf\\x00\\x00\\x01qn\\x19\\x8b \u0026#34; 127.0.0.1:6379\u0026gt; memory stats . . . 21) \u0026#34;keys.count\u0026#34; 22) (integer) 100 23) \u0026#34;keys.bytes-per-key\u0026#34; 24) (integer) 873 25) \u0026#34;dataset.bytes\u0026#34; 26) (integer) 15720 You can see that the size of the data set is smaller, 15720 bytes vs 15976 bytes, a marginal difference, but with larger amounts of data, this difference increases.\nIn my case, cleaning and restructuring the data, and utilizing the above techniques, we brought down the memory usage from 2GB to less than 500MB.\nThe full code can be found on my Github for redis-util.\n Special mention to Rahul Chopda (@_RahulChopda) for his guidance! You have been a best mentor anyone could ask for!\n","permalink":"https://darshit.dev/posts/reduce-redis-memory-usage/","summary":"Yes, you read that right.\nTo give you some context, some time ago, our (my org\u0026rsquo;s) Redis usage was un-tracked \u0026ndash; meaning we didn\u0026rsquo;t know why our Redis memory was being occupied as much as it was.","title":"How to achieve a 50% reduction in Redis memory usage"},{"content":"IntelliJ IDEA is an awesome IDE, and a lesser known and used feature is Live Templates.\nLive Templates enable you to use code snippets with just a few keystrokes. A lot of great ones are provided out-of-the-box by IntelliJ. You can view them using the shortcut press Double Shift and then typing Live Templates. The shortcut works regardless of the OS you\u0026rsquo;re currently using (and I am too lazy to specify OS specific menus).\nSome of the examples of Live Templates are:\nTyping psvm replaces it with\npublic static void main(String[] args){ } Typing psfs magically turns it into\npublic static final String I was recently refactoring a lot of classes and I had to replace a lot of legacy logging initialization statements to using slf4j logging library like the following:\nimport org.slf4j.Logger; import org.slf4j.LoggerFactory; public class LoggerTest { public static final Logger logger = LoggerFactory.getLogger(LoggerTest.class); } I had more than 30 different classes to refactor as the above, and I certainly didn\u0026rsquo;t want to painstakingly write everything by hand again (confirms that I\u0026rsquo;m lazy).\nFortunately, IntelliJ Live Templates came to my rescue! I fired up the Live Templates menu using the shortcut mentioned above, and clicked on the + button at the top right.\nI then clicked on Live Template button. The UI now points to the bottom which asks you to put an abbreviation.\nLet\u0026rsquo;s input the abbreviation as psfl which stands for public static final Logger, which can be also put in the description.\nWrite the following code in the Template text box:\npublic static final Logger logger = LoggerFactory.getLogger(); But hang on, the IDE gives us a warning to define a context where it would be used at. We want the template to be only used in Java, so we click on the Define button, and select Java.\nYou may now notice the IDE now applies syntax highlighting on the template.\nWait, we are still not there yet. I certainly don\u0026rsquo;t want to manually write every class name inside the getLogger function! At this point, I was not sure how I could achieve that. Cue in a bit of googling, stackoverflow again came to the rescue.\nI found the following answer: https://stackoverflow.com/a/8552882/4840501\npublic static final org.slf4j.Logger logger = org.slf4j.LoggerFactory.getLogger($CLASS_NAME$); $END$ So I copy-pasted the code in my template screen(what did you expect? :P)\nYou\u0026rsquo;d then need to define what $CLASS_NAME$ means. To do that, click on the Edit Variables button and select className() in the Expression box.\nThe $END$ variable means where you want your cursor at, after the template is applied.\nClick on Apply and Ok.\nWe\u0026rsquo;re done!\nFire up your classes and refactor with 10x speed!\nRelevant link: https://www.jetbrains.com/help/idea/creating-and-editing-live-templates.html\n","permalink":"https://darshit.dev/posts/using-intellij-idea-live-templates/","summary":"IntelliJ IDEA is an awesome IDE, and a lesser known and used feature is Live Templates.\nLive Templates enable you to use code snippets with just a few keystrokes. A lot of great ones are provided out-of-the-box by IntelliJ.","title":"Using IntelliJ IDEA Live Templates"},{"content":"","permalink":"https://darshit.dev/search/","summary":"search","title":"Search"}]